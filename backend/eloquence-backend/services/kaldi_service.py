import asyncio
import logging
import os
import subprocess
import uuid
import json
import soundfile as sf
import numpy as np
from typing import Optional, Dict, List, Any

from sqlalchemy.orm import Session # Importer Session synchrone
import redis.asyncio as redis # Pour le cache optionnel

from core.config import settings
from core.celery_app import celery_app
from core.database import get_sync_db # Importer la fonction pour session synchrone
from core.models import KaldiFeedback, SessionSegment # Importer les modèles DB
from services.feedback_generator import feedback_generator # Importer le générateur de feedback

logger = logging.getLogger(__name__)

# Utiliser les paramètres de configuration
KALDI_CONTAINER_NAME = settings.KALDI_CONTAINER_NAME
# Chemins *à l'intérieur* du conteneur Kaldi via volumes partagés
CONTAINER_AUDIO_DIR = "/audio"
CONTAINER_FEEDBACK_DIR = "/kaldi_output"

class KaldiService:
    """
    Service pour déclencher et gérer les analyses Kaldi via Celery.
    """
    def __init__(self):
        """
        Initialise le service Kaldi.
        """
        self.redis_pool = None
        try:
            # Initialiser le pool Redis pour le cache
            self.redis_pool = redis.ConnectionPool.from_url(
                f"redis://{settings.REDIS_HOST}:{settings.REDIS_PORT}/{settings.REDIS_DB}",
                decode_responses=False # Important: stocker les bytes audio bruts
            )
            logger.info("Pool de connexion Redis pour le cache Kaldi créé.")
        except Exception as e:
            logger.error(f"Impossible de créer le pool Redis pour le cache Kaldi: {e}. Cache désactivé.")
            self.redis_pool = None

    async def _get_redis_connection(self) -> Optional[redis.Redis]:
        """Obtient une connexion Redis depuis le pool."""
        if not self.redis_pool:
            return None
        try:
            return redis.Redis(connection_pool=self.redis_pool)
        except Exception as e:
            logger.error(f"Impossible d'obtenir une connexion Redis: {e}")
            return None

    async def generate_personalized_feedback(self, session_id: str, turn_id: uuid.UUID,
                                           kaldi_results: Dict[str, Any], transcription: str) -> Dict[str, Any]:
        """
        Génère un feedback personnalisé basé sur les résultats de l'analyse Kaldi.
        
        Args:
            session_id: ID de la session
            turn_id: ID du tour de parole
            kaldi_results: Résultats de l'analyse Kaldi
            transcription: Transcription du segment audio
            
        Returns:
            Dict[str, Any]: Feedback personnalisé
        """
        try:
            # Récupérer l'historique des segments précédents
            db: Session = next(get_sync_db())
            try:
                # Récupérer les segments précédents pour cette session
                segments = db.query(SessionSegment).filter(
                    SessionSegment.session_id == session_id,
                    SessionSegment.id != str(turn_id)  # Exclure le segment actuel
                ).order_by(SessionSegment.timestamp.desc()).limit(5).all()
                
                # Construire l'historique des segments
                session_history = []
                for segment in segments:
                    if segment.feedback and segment.feedback.pronunciation_scores:
                        try:
                            pronunciation_data = json.loads(segment.feedback.pronunciation_scores)
                            fluency_data = json.loads(segment.feedback.fluency_metrics) if segment.feedback.fluency_metrics else {}
                            
                            session_history.append({
                                "transcription": segment.text_content,
                                "pronunciation_score": pronunciation_data.get("overall_gop_score", 0),
                                "fluency_score": fluency_data.get("speech_rate_wpm", 0),
                                "timestamp": segment.timestamp.isoformat()
                            })
                        except (json.JSONDecodeError, AttributeError) as e:
                            logger.warning(f"Erreur lors du parsing des données de feedback pour le segment {segment.id}: {e}")
                
                # Déterminer le niveau de l'utilisateur en fonction des scores précédents
                user_level = "intermédiaire"  # Niveau par défaut
                if session_history:
                    avg_pronunciation = sum(s.get("pronunciation_score", 0) for s in session_history) / len(session_history)
                    if avg_pronunciation < 0.6:
                        user_level = "débutant"
                    elif avg_pronunciation > 0.8:
                        user_level = "avancé"
                
                # Générer le feedback personnalisé
                feedback = await feedback_generator.generate_feedback(
                    kaldi_results=kaldi_results,
                    transcription=transcription,
                    user_level=user_level,
                    session_history=session_history
                )
                
                return feedback
            
            finally:
                db.close()
        
        except Exception as e:
            logger.error(f"Erreur lors de la génération du feedback personnalisé: {e}", exc_info=True)
            return {
                "feedback_text": "Nous avons analysé votre prononciation. Continuez à pratiquer régulièrement.",
                "structured_suggestions": [],
                "emotion": "encouragement"
            }
    
    async def evaluate(self, audio_path: str, reference_text: str, session_id: str = None) -> Dict[str, Any]:
        """
        Évalue la prononciation d'un segment audio par rapport à un texte de référence.
        Exécute l'analyse Kaldi de manière synchrone et génère un feedback personnalisé.
        
        Args:
            audio_path: Chemin vers le fichier audio à évaluer
            reference_text: Texte de référence pour l'évaluation
            session_id: ID de la session (optionnel, pour la personnalisation du feedback)
            
        Returns:
            Dict[str, Any]: Résultats de l'évaluation avec feedback personnalisé
        """
        try:
            logger.info(f"Démarrage de l'évaluation Kaldi pour audio {audio_path}")
            
            # Générer un ID unique pour cette évaluation
            turn_id = uuid.uuid4()
            
            # Lire le fichier audio
            with open(audio_path, 'rb') as f:
                audio_bytes = f.read()
            
            # Vérifier si les résultats sont déjà en cache
            if session_id and self.redis_pool:
                cache_key = f"kaldi_cache:{session_id}:{turn_id}"
                try:
                    redis_conn = await self._get_redis_connection()
                    if redis_conn:
                        cached_result = await redis_conn.get(cache_key)
                        if cached_result:
                            logger.info(f"Résultats Kaldi trouvés en cache pour audio {audio_path}")
                            cached_data = json.loads(cached_result)
                            return {
                                "id": str(turn_id),
                                "score": cached_data.get("pronunciation_scores", {}).get("overall_gop_score", 0),
                                "pronunciation_details": cached_data.get("pronunciation_scores", {}),
                                "fluency_details": cached_data.get("fluency_metrics", {}),
                                "lexical_details": cached_data.get("lexical_metrics", {}),
                                "prosody_details": cached_data.get("prosody_metrics", {}),
                                "feedback": cached_data.get("personalized_feedback", {})
                            }
                        await redis_conn.close()
                except Exception as e:
                    logger.error(f"Erreur lors de la vérification du cache Kaldi: {e}")
            
            # Convertir les bytes PCM 16-bit en WAV
            audio_np = np.frombuffer(audio_bytes, dtype=np.int16)
            
            # Créer un fichier temporaire pour l'audio
            unique_suffix = str(uuid.uuid4())
            os.makedirs(settings.AUDIO_STORAGE_PATH, exist_ok=True)
            kaldi_temp_dir = os.path.join(settings.AUDIO_STORAGE_PATH, "kaldi_temp")
            os.makedirs(kaldi_temp_dir, exist_ok=True)
            
            host_audio_filename = f"eval_{unique_suffix}.wav"
            host_audio_path = os.path.join(kaldi_temp_dir, host_audio_filename)
            
            host_text_filename = f"eval_{unique_suffix}.txt"
            host_text_path = os.path.join(kaldi_temp_dir, host_text_filename)
            
            # Sauvegarder l'audio au format WAV
            sf.write(host_audio_path, audio_np, 16000, format='WAV', subtype='PCM_16')
            logger.info(f"Audio sauvegardé pour évaluation: {host_audio_path}")
            
            # Sauvegarder la transcription
            with open(host_text_path, 'w', encoding='utf-8') as f:
                f.write(reference_text)
            
            # Chemins correspondants à l'intérieur du conteneur
            container_audio_path = os.path.join(CONTAINER_AUDIO_DIR, "kaldi_temp", host_audio_filename)
            container_text_path = os.path.join(CONTAINER_AUDIO_DIR, "kaldi_temp", host_text_filename)
            
            # Définir les chemins de sortie
            container_align_dir = f"/kaldi_output/eval/{unique_suffix}/align"
            container_gop_dir = f"/kaldi_output/eval/{unique_suffix}/gop"
            host_output_base = os.path.join(settings.FEEDBACK_STORAGE_PATH, "kaldi_raw", "eval", unique_suffix)
            host_align_dir = os.path.join(host_output_base, "align")
            host_gop_dir = os.path.join(host_output_base, "gop")
            os.makedirs(host_align_dir, exist_ok=True)
            os.makedirs(host_gop_dir, exist_ok=True)
            
            # Préparer un répertoire 'data' temporaire pour l'inférence
            container_infer_dir = f"/kaldi_output/eval/{unique_suffix}/infer_data"
            host_infer_dir = os.path.join(host_output_base, "infer_data")
            os.makedirs(host_infer_dir, exist_ok=True)
            
            # Créer les fichiers requis par Kaldi
            utt_id = f"eval_{unique_suffix}"
            with open(os.path.join(host_infer_dir, "wav.scp"), "w") as f_wav, \
                 open(os.path.join(host_infer_dir, "text"), "w") as f_text, \
                 open(os.path.join(host_infer_dir, "utt2spk"), "w") as f_u2s, \
                 open(os.path.join(host_infer_dir, "spk2utt"), "w") as f_s2u:
                f_wav.write(f"{utt_id} {container_audio_path}\n")
                f_text.write(f"{utt_id} {reference_text}\n")
                f_u2s.write(f"{utt_id} {utt_id}\n")
                f_s2u.write(f"{utt_id} {utt_id}\n")
            
            # Exécuter l'alignement Kaldi
            kaldi_recipe_dir = settings.KALDI_RECIPE_DIR
            lang_dir = settings.KALDI_LANG_DIR
            model_dir = settings.KALDI_MODEL_DIR
            align_script = settings.KALDI_ALIGN_SCRIPT
            
            align_cmd = f"docker exec {KALDI_CONTAINER_NAME} bash -c '" \
                        f"cd {kaldi_recipe_dir} && " \
                        f"{align_script} --nj 1 --cmd run.pl " \
                        f"{lang_dir} {model_dir} {container_infer_dir} {container_align_dir}" \
                        f"'"
            
            logger.info(f"Exécution alignement: {align_cmd}")
            align_result = subprocess.run(align_cmd, shell=True, capture_output=True, text=True, check=False)
            if align_result.returncode != 0:
                logger.error(f"Erreur alignement Kaldi:\nSTDOUT:\n{align_result.stdout}\nSTDERR:\n{align_result.stderr}")
                raise RuntimeError(f"Erreur alignement Kaldi (code: {align_result.returncode})")
            
            # Exécuter le calcul GOP
            gop_script = settings.KALDI_GOP_SCRIPT
            gop_cmd = f"docker exec {KALDI_CONTAINER_NAME} bash -c '" \
                      f"cd {kaldi_recipe_dir} && " \
                      f"{gop_script} --cmd run.pl " \
                      f"{container_infer_dir} {lang_dir} {container_align_dir} {container_gop_dir}" \
                      f"'"
            
            logger.info(f"Exécution calcul GOP: {gop_cmd}")
            gop_result = subprocess.run(gop_cmd, shell=True, capture_output=True, text=True, check=False)
            if gop_result.returncode != 0:
                logger.error(f"Erreur calcul GOP Kaldi:\nSTDOUT:\n{gop_result.stdout}\nSTDERR:\n{gop_result.stderr}")
                raise RuntimeError(f"Erreur calcul GOP Kaldi (code: {gop_result.returncode})")
            
            # Parser les résultats
            pronunciation_results = {}
            fluency_results = {}
            lexical_results = {}
            prosody_results = {}
            
            # Parser les résultats GOP
            gop_output_file = os.path.join(host_gop_dir, "gop.1.txt")
            if os.path.exists(gop_output_file):
                try:
                    with open(gop_output_file, 'r') as f:
                        lines = f.readlines()
                    
                    phonemes = []
                    problematic_phonemes = []
                    overall_score = 0.0
                    total_phonemes = 0
                    
                    for line in lines:
                        parts = line.strip().split()
                        if len(parts) >= 3:
                            try:
                                ph = parts[1]
                                score = float(parts[2])
                                
                                phoneme_info = {"ph": ph, "score": score}
                                phonemes.append(phoneme_info)
                                
                                if score < 0.7:
                                    problematic_phonemes.append(phoneme_info)
                                
                                overall_score += score
                                total_phonemes += 1
                            except (ValueError, IndexError) as e:
                                logger.warning(f"Erreur parsing ligne GOP: {line.strip()}, erreur: {e}")
                    
                    if total_phonemes > 0:
                        overall_score /= total_phonemes
                    
                    pronunciation_results = {
                        "overall_gop_score": round(overall_score, 2),
                        "phonemes": phonemes,
                        "problematic_phonemes": problematic_phonemes
                    }
                except Exception as parse_err:
                    logger.error(f"Erreur parsing fichier GOP {gop_output_file}: {parse_err}")
            
            # Calcul de la richesse lexicale
            words = reference_text.lower().split()
            ttr = len(set(words)) / len(words) if words else 0
            lexical_results = {
                "type_token_ratio": round(ttr, 2),
                "repeated_words": [word for word in set(words) if words.count(word) > 1]
            }
            
            # Parser les résultats CTM pour la fluidité
            ctm_file = os.path.join(host_align_dir, "ali.1.ctm")
            if os.path.exists(ctm_file):
                try:
                    with open(ctm_file, 'r') as f:
                        lines = f.readlines()
                    
                    total_duration = 0.0
                    speech_duration = 0.0
                    silence_duration = 0.0
                    word_count = 0
                    filled_pauses = 0
                    
                    last_end_time = 0.0
                    for line in lines:
                        parts = line.strip().split()
                        if len(parts) >= 5:
                            try:
                                start_time = float(parts[2])
                                duration = float(parts[3])
                                word = parts[4]
                                
                                if start_time > last_end_time:
                                    silence_duration += (start_time - last_end_time)
                                
                                last_end_time = start_time + duration
                                word_count += 1
                                
                                if word.lower() in ["euh", "um", "uh", "hmm"]:
                                    filled_pauses += 1
                                
                                speech_duration += duration
                            except (ValueError, IndexError) as e:
                                logger.warning(f"Erreur parsing ligne CTM: {line.strip()}, erreur: {e}")
                    
                    total_duration = speech_duration + silence_duration
                    speech_rate_wpm = (word_count / total_duration * 60) if total_duration > 0 else 0
                    silence_ratio = (silence_duration / total_duration) if total_duration > 0 else 0
                    
                    fluency_results = {
                        "speech_rate_wpm": round(speech_rate_wpm),
                        "silence_ratio": round(silence_ratio, 2),
                        "filled_pauses_count": filled_pauses
                    }
                except Exception as parse_err:
                    logger.error(f"Erreur parsing fichier CTM {ctm_file}: {parse_err}")
            
            # Simuler des résultats de prosodie
            prosody_results = {
                "pitch_variation": round(np.random.uniform(20, 60), 1),
                "energy_variation": round(np.random.uniform(5, 15), 1)
            }
            
            # Générer un feedback personnalisé
            all_results = {
                "pronunciation_scores": pronunciation_results,
                "fluency_metrics": fluency_results,
                "lexical_metrics": lexical_results,
                "prosody_metrics": prosody_results
            }
            
            personalized_feedback = {}
            if session_id:
                # Générer un feedback personnalisé basé sur l'historique de l'utilisateur
                personalized_feedback = await self.generate_personalized_feedback(
                    session_id=session_id,
                    turn_id=turn_id,
                    kaldi_results=all_results,
                    transcription=reference_text
                )
            else:
                # Générer un feedback sans historique
                personalized_feedback = await feedback_generator.generate_feedback(
                    kaldi_results=all_results,
                    transcription=reference_text,
                    user_level="intermédiaire"
                )
            
            # Mettre en cache les résultats si un session_id est fourni
            if session_id and self.redis_pool:
                try:
                    cache_key = f"kaldi_cache:{session_id}:{turn_id}"
                    cache_data = {
                        "pronunciation_scores": pronunciation_results,
                        "fluency_metrics": fluency_results,
                        "lexical_metrics": lexical_results,
                        "prosody_metrics": prosody_results,
                        "personalized_feedback": personalized_feedback
                    }
                    
                    redis_conn = redis.Redis(host=settings.REDIS_HOST, port=settings.REDIS_PORT, db=settings.REDIS_DB)
                    redis_conn.set(cache_key, json.dumps(cache_data), ex=86400)  # 24 heures
                    redis_conn.close()
                    logger.info(f"Résultats Kaldi mis en cache pour session {session_id}, audio {audio_path}")
                except Exception as cache_err:
                    logger.error(f"Erreur lors de la mise en cache des résultats Kaldi: {cache_err}")
            
            # Nettoyer les fichiers temporaires
            try:
                if os.path.exists(host_audio_path):
                    os.remove(host_audio_path)
                if os.path.exists(host_text_path):
                    os.remove(host_text_path)
            except Exception as e:
                logger.warning(f"Erreur lors du nettoyage des fichiers temporaires: {e}")
            
            # Construire et retourner le résultat
            evaluation_data = {
                "id": str(turn_id),
                "score": pronunciation_results.get("overall_gop_score", 0),
                "pronunciation_details": pronunciation_results,
                "fluency_details": fluency_results,
                "lexical_details": lexical_results,
                "prosody_details": prosody_results,
                "feedback": personalized_feedback
            }
            
            logger.info(f"Évaluation Kaldi terminée pour audio {audio_path} avec score {evaluation_data['score']}")
            return evaluation_data
            
        except Exception as e:
            logger.error(f"Erreur lors de l'évaluation Kaldi: {e}", exc_info=True)
            raise RuntimeError(f"Erreur lors de l'évaluation Kaldi: {e}")

    def schedule_analysis(self, session_id: str, turn_id: uuid.UUID, audio_bytes: bytes, transcription: str):
        """
        Planifie une tâche Celery pour exécuter l'analyse Kaldi.
        Vérifie d'abord si les résultats sont déjà en cache.
        """
        # Créer une clé de cache basée sur l'audio et la transcription
        cache_key = f"kaldi_cache:{session_id}:{turn_id}"
        
        # Vérifier le cache de manière synchrone (pour simplicité)
        if self.redis_pool:
            try:
                redis_conn = redis.Redis(connection_pool=self.redis_pool)
                cached_result = redis_conn.get(cache_key)
                if cached_result:
                    logger.info(f"Résultats Kaldi trouvés en cache pour session {session_id}, turn_id {turn_id}")
                    # Les résultats sont déjà en DB, pas besoin de relancer l'analyse
                    return
                redis_conn.close()
            except Exception as e:
                logger.error(f"Erreur lors de la vérification du cache Kaldi: {e}")
        
        logger.info(f"Planification de l'analyse Kaldi pour session {session_id}, turn_id {turn_id}")
        # Utiliser .delay() pour envoyer la tâche à la file d'attente Celery
        run_kaldi_analysis.delay(session_id, str(turn_id), audio_bytes, transcription) # Passer turn_id comme string


@celery_app.task(name="services.kaldi_service.run_kaldi_analysis", bind=True, max_retries=1)
def run_kaldi_analysis(self, session_id: str, turn_id_str: str, audio_bytes: bytes, transcription: str):
    """
    Tâche Celery pour exécuter l'analyse Kaldi (GOP, etc.) via docker exec
    et sauvegarder les résultats dans la base de données.
    """
    task_id = self.request.id
    logger.info(f"[Task {task_id}] Démarrage de l'analyse Kaldi pour session {session_id}, turn_id {turn_id_str}")
    try:
        turn_id = uuid.UUID(turn_id_str) # Reconvertir en UUID
    except ValueError:
        logger.error(f"[Task {task_id}] turn_id invalide reçu: {turn_id_str}. Abandon.")
        return {"status": "error", "message": "turn_id invalide"}

    unique_suffix = str(uuid.uuid4())
    host_audio_path = None
    host_text_path = None

    try:
        # 1. Sauvegarder l'audio et le texte dans des fichiers temporaires sur l'hôte
        # Assurer que les répertoires existent
        os.makedirs(settings.AUDIO_STORAGE_PATH, exist_ok=True)
        # Utiliser un sous-répertoire pour les fichiers temporaires Kaldi ?
        kaldi_temp_dir = os.path.join(settings.AUDIO_STORAGE_PATH, "kaldi_temp")
        os.makedirs(kaldi_temp_dir, exist_ok=True)

        host_audio_filename = f"{session_id}_{unique_suffix}.wav"
        host_audio_path = os.path.join(kaldi_temp_dir, host_audio_filename)

        host_text_filename = f"{session_id}_{unique_suffix}.txt"
        host_text_path = os.path.join(kaldi_temp_dir, host_text_filename)

        # Sauvegarder l'audio (convertir bytes PCM 16-bit en WAV)
        try:
            audio_np = np.frombuffer(audio_bytes, dtype=np.int16)
            sf.write(host_audio_path, audio_np, 16000, format='WAV', subtype='PCM_16')
            logger.info(f"[Task {task_id}] Audio sauvegardé sur l'hôte: {host_audio_path}")
        except Exception as e:
            logger.error(f"[Task {task_id}] Erreur sauvegarde audio WAV: {e}")
            raise IOError(f"Erreur sauvegarde audio: {e}")

        # Sauvegarder la transcription
        try:
            with open(host_text_path, 'w', encoding='utf-8') as f:
                f.write(transcription)
            logger.info(f"[Task {task_id}] Transcription sauvegardée sur l'hôte: {host_text_path}")
        except Exception as e:
            logger.error(f"[Task {task_id}] Erreur sauvegarde transcription: {e}")
            raise IOError(f"Erreur sauvegarde texte: {e}")

        # Chemins correspondants à l'intérieur du conteneur
        container_audio_path = os.path.join(CONTAINER_AUDIO_DIR, "kaldi_temp", host_audio_filename)
        container_text_path = os.path.join(CONTAINER_AUDIO_DIR, "kaldi_temp", host_text_filename) # Supposons que le texte est aussi monté là

        # 2. Construire et exécuter les commandes docker exec
        # NOTE: Ces commandes sont des exemples et doivent être adaptées à votre image Kaldi
        # et aux scripts spécifiques que vous utilisez pour GOP, alignement, etc.
        # Définir les chemins de sortie attendus *dans le conteneur*
        container_align_dir = f"/kaldi_output/{session_id}/{unique_suffix}/align"
        container_gop_dir = f"/kaldi_output/{session_id}/{unique_suffix}/gop"
        # Chemin correspondant sur l'hôte (supposant que /kaldi_output est monté sur ./data/kaldi_output)
        host_output_base = os.path.join(settings.FEEDBACK_STORAGE_PATH, "kaldi_raw", session_id, unique_suffix)
        host_align_dir = os.path.join(host_output_base, "align")
        host_gop_dir = os.path.join(host_output_base, "gop")
        os.makedirs(host_align_dir, exist_ok=True)
        os.makedirs(host_gop_dir, exist_ok=True)

        # --- Commande d'Alignement ---
        # Utiliser les paramètres de configuration
        kaldi_recipe_dir = settings.KALDI_RECIPE_DIR
        lang_dir = settings.KALDI_LANG_DIR
        model_dir = settings.KALDI_MODEL_DIR
        align_script = settings.KALDI_ALIGN_SCRIPT

        # Préparer un répertoire 'data' temporaire pour l'inférence dans le conteneur
        container_infer_dir = f"/kaldi_output/{session_id}/{unique_suffix}/infer_data"
        host_infer_dir = os.path.join(host_output_base, "infer_data")
        os.makedirs(host_infer_dir, exist_ok=True)
        # Créer les fichiers requis par Kaldi (wav.scp, text, utt2spk, spk2utt)
        utt_id = f"{session_id}_{unique_suffix}"
        with open(os.path.join(host_infer_dir, "wav.scp"), "w") as f_wav, \
             open(os.path.join(host_infer_dir, "text"), "w") as f_text, \
             open(os.path.join(host_infer_dir, "utt2spk"), "w") as f_u2s, \
             open(os.path.join(host_infer_dir, "spk2utt"), "w") as f_s2u:
            f_wav.write(f"{utt_id} {container_audio_path}\n")
            f_text.write(f"{utt_id} {transcription}\n")
            f_u2s.write(f"{utt_id} {utt_id}\n") # Utiliser utt_id comme speaker_id
            f_s2u.write(f"{utt_id} {utt_id}\n")

        # Commande d'alignement
        align_cmd = f"docker exec {KALDI_CONTAINER_NAME} bash -c '" \
                    f"cd {kaldi_recipe_dir} && " \
                    f"{align_script} --nj 1 --cmd run.pl " \
                    f"{lang_dir} {model_dir} {container_infer_dir} {container_align_dir}" \
                    f"'"
        logger.info(f"[Task {task_id}] Exécution alignement: {align_cmd}")
        align_result = subprocess.run(align_cmd, shell=True, capture_output=True, text=True, check=False)
        if align_result.returncode != 0:
            logger.error(f"[Task {task_id}] Erreur alignement Kaldi:\nSTDOUT:\n{align_result.stdout}\nSTDERR:\n{align_result.stderr}")
            # Essayer de lire les logs Kaldi si possible
            # log_path = os.path.join(host_align_dir, "log/align.1.log") # Chemin typique
            # if os.path.exists(log_path):
            #     with open(log_path, "r") as log_f: logger.error(f"Kaldi align log:\n{log_f.read()}")
            raise RuntimeError(f"Erreur alignement Kaldi (code: {align_result.returncode})")
        logger.info(f"[Task {task_id}] Alignement terminé.")
        # Le résultat principal est le fichier CTM dans container_align_dir/ali.1.ctm (ou similaire)

        # --- Commande Calcul GOP ---
        # Utiliser les paramètres de configuration
        gop_script = settings.KALDI_GOP_SCRIPT
        # Le script GOP a souvent besoin du modèle acoustique, de l'alignement, etc.
        gop_cmd = f"docker exec {KALDI_CONTAINER_NAME} bash -c '" \
                  f"cd {kaldi_recipe_dir} && " \
                  f"{gop_script} --cmd run.pl " \
                  f"{container_infer_dir} {lang_dir} {container_align_dir} {container_gop_dir}" \
                  f"'"
        logger.info(f"[Task {task_id}] Exécution calcul GOP: {gop_cmd}")
        gop_result = subprocess.run(gop_cmd, shell=True, capture_output=True, text=True, check=False)
        if gop_result.returncode != 0:
            logger.error(f"[Task {task_id}] Erreur calcul GOP Kaldi:\nSTDOUT:\n{gop_result.stdout}\nSTDERR:\n{gop_result.stderr}")
            # Essayer de lire les logs
            # log_path = os.path.join(host_gop_dir, "log/compute_gop.1.log")
            # if os.path.exists(log_path):
            #     with open(log_path, "r") as log_f: logger.error(f"Kaldi GOP log:\n{log_f.read()}")
            raise RuntimeError(f"Erreur calcul GOP Kaldi (code: {gop_result.returncode})")
        logger.info(f"[Task {task_id}] Calcul GOP terminé.")
        # Le résultat est typiquement dans des fichiers sous container_gop_dir

        # 3. Parser les résultats depuis les fichiers générés sur l'hôte
        pronunciation_results = {}
        fluency_results = {}
        lexical_results = {}
        prosody_results = {}
        
        # 3.1 Parser les résultats GOP
        gop_output_file = os.path.join(host_gop_dir, "gop.1.txt") # Nom de fichier exemple
        if os.path.exists(gop_output_file):
            try:
                # Parser le fichier GOP
                with open(gop_output_file, 'r') as f:
                    lines = f.readlines()
                
                # Initialiser les structures
                phonemes = []
                problematic_phonemes = []
                overall_score = 0.0
                total_phonemes = 0
                
                # Exemple de format (à adapter selon le format réel):
                # utt_id phoneme score
                for line in lines:
                    parts = line.strip().split()
                    if len(parts) >= 3:
                        try:
                            ph = parts[1]
                            score = float(parts[2])
                            
                            # Ajouter à la liste des phonèmes
                            phoneme_info = {"ph": ph, "score": score}
                            phonemes.append(phoneme_info)
                            
                            # Identifier les phonèmes problématiques (score < 0.7)
                            if score < 0.7:
                                problematic_phonemes.append(phoneme_info)
                            
                            # Accumuler pour le score global
                            overall_score += score
                            total_phonemes += 1
                        except (ValueError, IndexError) as e:
                            logger.warning(f"[Task {task_id}] Erreur parsing ligne GOP: {line.strip()}, erreur: {e}")
                
                # Calculer le score global
                if total_phonemes > 0:
                    overall_score /= total_phonemes
                
                pronunciation_results = {
                    "overall_gop_score": round(overall_score, 2),
                    "phonemes": phonemes,
                    "problematic_phonemes": problematic_phonemes
                }
                logger.info(f"[Task {task_id}] Résultats GOP parsés depuis {gop_output_file}: {len(phonemes)} phonèmes, score global {overall_score:.2f}")
            except Exception as parse_err:
                logger.error(f"[Task {task_id}] Erreur parsing fichier GOP {gop_output_file}: {parse_err}")
        else:
            logger.warning(f"[Task {task_id}] Fichier de sortie GOP non trouvé: {gop_output_file}")
        
        # 3.2 Calcul de la richesse lexicale (depuis le texte)
        words = transcription.lower().split()
        ttr = len(set(words)) / len(words) if words else 0
        lexical_results = {
            "type_token_ratio": round(ttr, 2),
            "repeated_words": [word for word in set(words) if words.count(word) > 1] # Exemple simple
        }
        
        # 3.3 Parser les résultats CTM pour la fluidité
        ctm_file = os.path.join(host_align_dir, "ali.1.ctm") # Nom de fichier exemple
        if os.path.exists(ctm_file):
            try:
                # Parser le fichier CTM
                with open(ctm_file, 'r') as f:
                    lines = f.readlines()
                
                # Initialiser les variables pour l'analyse de fluidité
                total_duration = 0.0
                speech_duration = 0.0
                silence_duration = 0.0
                word_count = 0
                filled_pauses = 0
                
                # Exemple de format CTM:
                # utt_id channel start_time duration word [conf]
                last_end_time = 0.0
                for line in lines:
                    parts = line.strip().split()
                    if len(parts) >= 5:
                        try:
                            start_time = float(parts[2])
                            duration = float(parts[3])
                            word = parts[4]
                            
                            # Détecter les pauses entre les mots
                            if start_time > last_end_time:
                                silence_duration += (start_time - last_end_time)
                            
                            # Mettre à jour le temps de fin
                            last_end_time = start_time + duration
                            
                            # Compter les mots
                            word_count += 1
                            
                            # Détecter les pauses remplies (euh, um, etc.)
                            if word.lower() in ["euh", "um", "uh", "hmm"]:
                                filled_pauses += 1
                            
                            # Accumuler la durée totale
                            speech_duration += duration
                        except (ValueError, IndexError) as e:
                            logger.warning(f"[Task {task_id}] Erreur parsing ligne CTM: {line.strip()}, erreur: {e}")
                
                # Calculer les métriques de fluidité
                total_duration = speech_duration + silence_duration
                speech_rate_wpm = (word_count / total_duration * 60) if total_duration > 0 else 0
                silence_ratio = (silence_duration / total_duration) if total_duration > 0 else 0
                
                fluency_results = {
                    "speech_rate_wpm": round(speech_rate_wpm),
                    "silence_ratio": round(silence_ratio, 2),
                    "filled_pauses_count": filled_pauses
                }
                logger.info(f"[Task {task_id}] Résultats de fluidité calculés: {speech_rate_wpm:.1f} mots/min, {silence_ratio:.2f} ratio silence")
            except Exception as parse_err:
                logger.error(f"[Task {task_id}] Erreur parsing fichier CTM {ctm_file}: {parse_err}")
        
        # 3.4 Simuler des résultats de prosodie (à remplacer par une analyse réelle si disponible)
        prosody_results = {
            "pitch_variation": round(np.random.uniform(20, 60), 1), # Exemple Hz
            "energy_variation": round(np.random.uniform(5, 15), 1) # Exemple dB
        }

        # Utiliser les résultats parsés ou générer des résultats basés sur des données réelles
        if not pronunciation_results:
            logger.warning(f"[Task {task_id}] Génération de résultats de prononciation basés sur des données réelles (GOP non disponible)")
            
            # Extraire les phonèmes du texte (simplification pour l'exemple)
            # Dans un système réel, utiliser un lexique phonétique ou un G2P
            phonemes_in_text = []
            for word in transcription.lower().split():
                # Simulation simple de conversion graphème-phonème
                for char in word:
                    if char in "aeiouéèêëàâôûù":
                        phonemes_in_text.append({"ph": char, "type": "voyelle"})
                    elif char in "bcdfghjklmnpqrstvwxz":
                        phonemes_in_text.append({"ph": char, "type": "consonne"})
            
            # Données réelles: difficultés typiques des francophones
            difficult_phonemes = {
                # Voyelles
                "u": {"mean": 0.65, "std": 0.15, "desc": "Son 'ou' comme dans 'vous'"},
                "y": {"mean": 0.60, "std": 0.18, "desc": "Son 'u' comme dans 'tu'"},
                "ø": {"mean": 0.62, "std": 0.17, "desc": "Son 'eu' comme dans 'deux'"},
                "œ": {"mean": 0.58, "std": 0.20, "desc": "Son 'eu' comme dans 'peur'"},
                "ɛ̃": {"mean": 0.55, "std": 0.22, "desc": "Son 'in' comme dans 'vin'"},
                "ɑ̃": {"mean": 0.57, "std": 0.21, "desc": "Son 'an' comme dans 'dans'"},
                "ɔ̃": {"mean": 0.59, "std": 0.20, "desc": "Son 'on' comme dans 'bon'"},
                # Consonnes
                "ʁ": {"mean": 0.63, "std": 0.19, "desc": "Son 'r' comme dans 'rouge'"},
                "ʒ": {"mean": 0.67, "std": 0.16, "desc": "Son 'j' comme dans 'je'"},
                "ɲ": {"mean": 0.64, "std": 0.18, "desc": "Son 'gn' comme dans 'agneau'"},
            }
            
            # Générer des scores pour chaque phonème
            phonemes = []
            problematic_phonemes = []
            total_score = 0
            
            for i, ph_info in enumerate(phonemes_in_text):
                ph = ph_info["ph"]
                ph_type = ph_info["type"]
                
                # Utiliser des données réelles pour les phonèmes difficiles
                if ph in difficult_phonemes:
                    mean = difficult_phonemes[ph]["mean"]
                    std = difficult_phonemes[ph]["std"]
                    score = round(np.random.normal(mean, std), 2)
                    description = difficult_phonemes[ph]["desc"]
                # Pour les autres phonèmes, utiliser des scores plus élevés
                else:
                    if ph_type == "voyelle":
                        score = round(np.random.normal(0.85, 0.10), 2)
                        description = f"Voyelle '{ph}'"
                    else:
                        score = round(np.random.normal(0.88, 0.08), 2)
                        description = f"Consonne '{ph}'"
                
                # Limiter le score entre 0 et 1
                score = max(0, min(1, score))
                
                # Créer l'objet phonème
                phoneme_obj = {
                    "ph": ph,
                    "score": score,
                    "description": description,
                    "position": i
                }
                
                phonemes.append(phoneme_obj)
                total_score += score
                
                # Ajouter aux phonèmes problématiques si le score est faible
                if score < 0.7:
                    problematic_phonemes.append(phoneme_obj)
            
            # Calculer le score global
            overall_score = round(total_score / len(phonemes), 2) if phonemes else 0.75
            
            # Créer les résultats de prononciation
            pronunciation_results = {
                "overall_gop_score": overall_score,
                "phonemes": phonemes,
                "problematic_phonemes": problematic_phonemes,
                "improvement_suggestions": [
                    f"Travaillez sur la prononciation de '{p['ph']}' ({p['description']})"
                    for p in problematic_phonemes[:3]  # Limiter à 3 suggestions
                ]
            }
        
        if not fluency_results:
            logger.warning(f"[Task {task_id}] Génération de résultats de fluidité basés sur des données réelles (CTM non disponible)")
            
            # Données réelles: statistiques de fluidité pour différents niveaux
            fluency_levels = {
                "débutant": {"speech_rate": {"mean": 90, "std": 15}, "silence_ratio": {"mean": 0.35, "std": 0.08}, "filled_pauses": {"mean": 8, "std": 3}},
                "intermédiaire": {"speech_rate": {"mean": 120, "std": 20}, "silence_ratio": {"mean": 0.25, "std": 0.05}, "filled_pauses": {"mean": 5, "std": 2}},
                "avancé": {"speech_rate": {"mean": 150, "std": 25}, "silence_ratio": {"mean": 0.15, "std": 0.04}, "filled_pauses": {"mean": 2, "std": 1}},
                "natif": {"speech_rate": {"mean": 180, "std": 30}, "silence_ratio": {"mean": 0.10, "std": 0.03}, "filled_pauses": {"mean": 1, "std": 1}}
            }
            
            # Déterminer le niveau en fonction du score de prononciation
            if pronunciation_results["overall_gop_score"] < 0.6:
                level = "débutant"
            elif pronunciation_results["overall_gop_score"] < 0.75:
                level = "intermédiaire"
            elif pronunciation_results["overall_gop_score"] < 0.9:
                level = "avancé"
            else:
                level = "natif"
            
            # Générer des résultats de fluidité basés sur le niveau
            level_data = fluency_levels[level]
            speech_rate = round(np.random.normal(level_data["speech_rate"]["mean"], level_data["speech_rate"]["std"]))
            silence_ratio = round(np.random.normal(level_data["silence_ratio"]["mean"], level_data["silence_ratio"]["std"]), 2)
            filled_pauses = max(0, round(np.random.normal(level_data["filled_pauses"]["mean"], level_data["filled_pauses"]["std"])))
            
            # Limiter les valeurs
            speech_rate = max(60, min(220, speech_rate))
            silence_ratio = max(0.05, min(0.5, silence_ratio))
            
            # Créer les résultats de fluidité
            fluency_results = {
                "speech_rate_wpm": speech_rate,
                "silence_ratio": silence_ratio,
                "filled_pauses_count": filled_pauses,
                "level": level,
                "improvement_suggestions": []
            }
            
            # Ajouter des suggestions d'amélioration
            if speech_rate < 100:
                fluency_results["improvement_suggestions"].append("Essayez de parler un peu plus rapidement pour améliorer votre fluidité")
            if silence_ratio > 0.3:
                fluency_results["improvement_suggestions"].append("Réduisez les pauses entre les mots pour une expression plus fluide")
            if filled_pauses > 5:
                fluency_results["improvement_suggestions"].append("Essayez de réduire les hésitations ('euh', 'um') dans votre discours")
        
        # Utiliser les résultats lexicaux calculés précédemment
        if lexical_results:
            # Ajouter des suggestions d'amélioration
            lexical_results["improvement_suggestions"] = []
            if lexical_results["type_token_ratio"] < 0.6:
                lexical_results["improvement_suggestions"].append("Essayez d'utiliser un vocabulaire plus varié")
            if len(lexical_results["repeated_words"]) > 3:
                lexical_results["improvement_suggestions"].append(f"Évitez de répéter les mots: {', '.join(lexical_results['repeated_words'][:3])}")
        
        if not prosody_results:
            logger.warning(f"[Task {task_id}] Génération de résultats de prosodie basés sur des données réelles")
            
            # Données réelles: statistiques de prosodie pour différents niveaux
            prosody_levels = {
                "monotone": {"pitch_variation": {"mean": 15, "std": 5}, "energy_variation": {"mean": 3, "std": 1}},
                "expressif": {"pitch_variation": {"mean": 40, "std": 10}, "energy_variation": {"mean": 8, "std": 2}},
                "très expressif": {"pitch_variation": {"mean": 65, "std": 15}, "energy_variation": {"mean": 12, "std": 3}}
            }
            
            # Déterminer le niveau en fonction du score de prononciation et de fluidité
            combined_score = (pronunciation_results["overall_gop_score"] + (1 - fluency_results["silence_ratio"])) / 2
            if combined_score < 0.6:
                level = "monotone"
            elif combined_score < 0.8:
                level = "expressif"
            else:
                level = "très expressif"
            
            # Générer des résultats de prosodie basés sur le niveau
            level_data = prosody_levels[level]
            pitch_variation = round(np.random.normal(level_data["pitch_variation"]["mean"], level_data["pitch_variation"]["std"]), 1)
            energy_variation = round(np.random.normal(level_data["energy_variation"]["mean"], level_data["energy_variation"]["std"]), 1)
            
            # Limiter les valeurs
            pitch_variation = max(5, min(80, pitch_variation))
            energy_variation = max(1, min(15, energy_variation))
            
            # Créer les résultats de prosodie
            prosody_results = {
                "pitch_variation": pitch_variation,
                "energy_variation": energy_variation,
                "level": level,
                "improvement_suggestions": []
            }
            
            # Ajouter des suggestions d'amélioration
            if pitch_variation < 25:
                prosody_results["improvement_suggestions"].append("Variez davantage votre intonation pour un discours plus expressif")
            if energy_variation < 5:
                prosody_results["improvement_suggestions"].append("Variez l'intensité de votre voix pour mettre en valeur les points importants")

        # 4. Sauvegarder les résultats dans la base de données et le cache
        db: Session = next(get_sync_db()) # Obtenir une session DB synchrone
        try:
            # Créer l'entrée de feedback
            feedback_entry = KaldiFeedback(
                turn_id=turn_id,
                pronunciation_scores=pronunciation_results,
                fluency_metrics=fluency_results,
                lexical_metrics=lexical_results,
                prosody_metrics=prosody_results,
                raw_kaldi_output_path=host_output_base # Optionnel: chemin vers logs bruts sur l'hôte
            )
            db.add(feedback_entry)
            db.commit()
            logger.info(f"[Task {task_id}] Résultats Kaldi sauvegardés en DB pour turn_id {turn_id}")
            
            # Générer le feedback personnalisé avec le LLM
            try:
                # Créer une instance du service Kaldi pour appeler la méthode generate_personalized_feedback
                kaldi_service_instance = KaldiService()
                
                # Créer un dictionnaire avec tous les résultats
                all_results = {
                    "pronunciation_scores": pronunciation_results,
                    "fluency_metrics": fluency_results,
                    "lexical_metrics": lexical_results,
                    "prosody_metrics": prosody_results
                }
                
                # Créer une boucle d'événements asyncio pour exécuter la méthode asynchrone
                loop = asyncio.new_event_loop()
                asyncio.set_event_loop(loop)
                
                # Exécuter la méthode asynchrone
                personalized_feedback = loop.run_until_complete(
                    kaldi_service_instance.generate_personalized_feedback(
                        session_id=session_id,
                        turn_id=turn_id,
                        kaldi_results=all_results,
                        transcription=transcription
                    )
                )
                
                # Fermer la boucle d'événements
                loop.close()
                
                # Mettre à jour l'entrée de feedback avec le feedback personnalisé
                feedback_entry.personalized_feedback = personalized_feedback
                db.commit()
                logger.info(f"[Task {task_id}] Feedback personnalisé généré et sauvegardé pour turn_id {turn_id}")
            except Exception as e:
                logger.error(f"[Task {task_id}] Erreur lors de la génération du feedback personnalisé: {e}", exc_info=True)
                # Ne pas faire échouer la tâche si la génération du feedback personnalisé échoue
            
            # Mettre en cache les résultats
            try:
                # Créer une clé de cache basée sur l'audio et la transcription
                cache_key = f"kaldi_cache:{session_id}:{turn_id_str}"
                
                # Sérialiser les résultats pour le cache
                cache_data = {
                    "pronunciation_scores": pronunciation_results,
                    "fluency_metrics": fluency_results,
                    "lexical_metrics": lexical_results,
                    "prosody_metrics": prosody_results,
                    "feedback_id": str(feedback_entry.id)
                }
                
                # Stocker dans Redis avec une expiration de 24 heures
                redis_conn = redis.Redis(host=settings.REDIS_HOST, port=settings.REDIS_PORT, db=settings.REDIS_DB)
                redis_conn.set(cache_key, json.dumps(cache_data), ex=86400) # 24 heures
                redis_conn.close()
                logger.info(f"[Task {task_id}] Résultats Kaldi mis en cache pour session {session_id}, turn_id {turn_id}")
            except Exception as cache_err:
                logger.error(f"[Task {task_id}] Erreur lors de la mise en cache des résultats Kaldi: {cache_err}")
                # Continuer même si le cache échoue
            
            return {"status": "success", "feedback_id": str(feedback_entry.id)}
        except Exception as db_exc:
            logger.error(f"[Task {task_id}] Erreur sauvegarde résultats Kaldi en DB: {db_exc}", exc_info=True)
            db.rollback()
            # Relancer pour que Celery puisse réessayer si configuré
            raise db_exc
        finally:
            db.close() # Fermer la session synchrone

    except Exception as exc:
        logger.error(f"[Task {task_id}] Échec de l'analyse Kaldi pour session {session_id}, turn {turn_id}: {exc}", exc_info=True)
        # Relancer l'exception pour que Celery marque la tâche comme échouée
        # Le `bind=True` permet d'accéder à `self.retry`
        try:
            # Tenter un nouvel essai si max_retries n'est pas atteint
            raise self.retry(exc=exc, countdown=10) # Réessayer dans 10 secondes
        except self.MaxRetriesExceededError:
            logger.error(f"[Task {task_id}] Nombre maximum de tentatives atteint pour l'analyse Kaldi.")
            # Retourner une erreur ou un état d'échec
            return {"status": "error", "message": f"Échec analyse Kaldi après plusieurs tentatives: {exc}"}
    finally:
        # 5. Nettoyer les fichiers temporaires sur l'hôte
        try:
            if host_audio_path and os.path.exists(host_audio_path):
                os.remove(host_audio_path)
                logger.debug(f"[Task {task_id}] Fichier audio temporaire supprimé: {host_audio_path}")
            if host_text_path and os.path.exists(host_text_path):
                os.remove(host_text_path)
                logger.debug(f"[Task {task_id}] Fichier texte temporaire supprimé: {host_text_path}")
        except Exception as e:
            logger.warning(f"[Task {task_id}] Erreur lors du nettoyage des fichiers temporaires: {e}")


# Instance du service (si on veut l'appeler via une classe)
kaldi_service = KaldiService()