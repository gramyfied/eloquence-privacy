"""
Agent LiveKit Moderne pour Coaching Vocal IA
Utilise le framework LiveKit Agents pour une intÃ©gration optimale
Pipeline: Audio â†’ Whisper ASR â†’ Mistral LLM â†’ Coqui TTS â†’ Audio
"""

import asyncio
import logging
import os
import tempfile
import httpx
import numpy as np
from typing import Optional
from dotenv import load_dotenv

from livekit.agents import (
    Agent,
    AgentSession,
    JobContext,
    RunContext,
    WorkerOptions,
    cli,
    function_tool,
)
import webrtcvad
from livekit import rtc

# Charger les variables d'environnement
load_dotenv()

# Configuration du logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger("LIVEKIT_AGENT_MODERNE")

class CustomSTT:
    """STT personnalisÃ© utilisant notre service Whisper"""
    
    def __init__(self, asr_url: str = "http://asr-service:8001/transcribe"):
        self.asr_url = asr_url
        logger.info(f"ğŸ¤ STT initialisÃ© avec URL: {asr_url}")
    
    async def transcribe(self, audio_data: bytes) -> Optional[str]:
        """Transcription audio via notre service Whisper"""
        try:
            # Sauvegarder temporairement l'audio
            with tempfile.NamedTemporaryFile(suffix='.wav', delete=False) as tmp_file:
                tmp_file.write(audio_data)
                tmp_file_path = tmp_file.name
            
            # Envoyer Ã  notre service ASR
            async with httpx.AsyncClient() as client:
                with open(tmp_file_path, 'rb') as audio_file:
                    files = {'file': ('audio.wav', audio_file, 'audio/wav')}
                    response = await client.post(
                        self.asr_url,
                        files=files,
                        timeout=30.0
                    )
                
                if response.status_code == 200:
                    result = response.json()
                    transcription = result.get('text', '').strip()
                    logger.info(f"ğŸ“ Transcription: '{transcription}'")
                    return transcription
                else:
                    logger.warning(f"âš ï¸ ASR erreur {response.status_code}")
                    return None
                    
        except Exception as e:
            logger.error(f"âŒ Erreur STT: {e}")
            return None
        finally:
            # Nettoyer le fichier temporaire
            try:
                os.unlink(tmp_file_path)
            except:
                pass

class CustomLLM:
    """LLM personnalisÃ© pour les rÃ©ponses de coaching vocal"""
    
    def __init__(self):
        self.conversation_history = []
        logger.info("ğŸ§  LLM initialisÃ© pour coaching vocal")
    
    async def generate_response(self, user_text: str, context: str = "") -> str:
        """GÃ©nÃ¨re une rÃ©ponse de coaching vocal"""
        try:
            # Ajouter Ã  l'historique
            self.conversation_history.append({"role": "user", "content": user_text})
            
            # RÃ©ponses de coaching vocal contextuelles
            coaching_responses = [
                f"Excellent ! Vous avez dit '{user_text}'. Votre diction est claire. Essayons maintenant de travailler sur l'intonation.",
                f"TrÃ¨s bien ! J'ai entendu '{user_text}'. Pouvez-vous rÃ©pÃ©ter en mettant plus d'Ã©motion dans votre voix ?",
                f"Parfait ! Votre prononciation de '{user_text}' s'amÃ©liore. Continuons avec un exercice de respiration.",
                f"Bravo ! Vous maÃ®trisez bien '{user_text}'. Essayons maintenant de varier le rythme de votre Ã©locution.",
                f"Formidable ! Votre expression '{user_text}' Ã©tait trÃ¨s naturelle. Travaillons sur la projection de votre voix."
            ]
            
            import random
            response = random.choice(coaching_responses)
            
            # Ajouter Ã  l'historique
            self.conversation_history.append({"role": "assistant", "content": response})
            
            logger.info(f"ğŸ§  RÃ©ponse LLM gÃ©nÃ©rÃ©e: '{response[:50]}...'")
            return response
            
        except Exception as e:
            logger.error(f"âŒ Erreur LLM: {e}")
            return "Je vous Ã©coute, continuez votre exercice de diction."

class CustomTTS:
    """TTS personnalisÃ© utilisant notre service Coqui TTS"""
    
    def __init__(self, tts_url: str = "http://tts-service:5002/api/tts"):
        self.tts_url = tts_url
        logger.info(f"ğŸ—£ï¸ TTS initialisÃ© avec URL: {tts_url}")
    
    async def synthesize(self, text: str) -> Optional[bytes]:
        """SynthÃ¨se vocale via notre service Coqui TTS"""
        try:
            async with httpx.AsyncClient() as client:
                response = await client.post(
                    self.tts_url,
                    json={'text': text},
                    timeout=15.0
                )
                
                if response.status_code == 200:
                    audio_data = response.content
                    logger.info(f"ğŸ—£ï¸ TTS gÃ©nÃ©rÃ©: {len(audio_data)} octets")
                    return audio_data
                else:
                    logger.warning(f"âš ï¸ TTS erreur {response.status_code}")
                    return None
                    
        except Exception as e:
            logger.error(f"âŒ Erreur TTS: {e}")
            return None

class CoachingVocalAgent(Agent):
    """Agent de coaching vocal intelligent"""
    
    def __init__(self):
        super().__init__(
            instructions="""Vous Ãªtes un coach vocal IA expert. Votre mission est d'aider les utilisateurs Ã  amÃ©liorer leur diction, leur Ã©locution et leur expression orale. 
            
            Vous devez :
            - Ã‰couter attentivement leur prononciation
            - Donner des conseils constructifs et encourageants
            - Proposer des exercices adaptÃ©s
            - Corriger les erreurs de diction avec bienveillance
            - Encourager la progression
            
            Soyez toujours positif, patient et professionnel."""
        )
        
        # Initialiser nos services personnalisÃ©s
        self.custom_stt = CustomSTT()
        self.custom_llm = CustomLLM()
        self.custom_tts = CustomTTS()
        
        # Compteurs de performance
        self.audio_frames_processed = 0
        self.transcriptions_made = 0
        self.responses_generated = 0
        
        logger.info("ğŸ¯ Agent de coaching vocal initialisÃ©")
    
    async def on_enter(self):
        """AppelÃ© quand l'agent entre dans la session"""
        logger.info("ğŸš€ Agent de coaching vocal activÃ©")
        
        # Message d'accueil
        welcome_message = """Bonjour ! Je suis votre coach vocal IA. 
        Je vais vous aider Ã  amÃ©liorer votre diction et votre expression orale. 
        Commencez par me dire quelques mots pour que je puisse Ã©valuer votre voix."""
        
        await self.session.generate_reply(instructions=welcome_message)
    
    async def process_audio_frame(self, audio_frame: rtc.AudioFrame) -> Optional[str]:
        """Traite une frame audio et retourne la transcription"""
        try:
            self.audio_frames_processed += 1
            
            # Convertir la frame en donnÃ©es audio
            audio_data = np.frombuffer(audio_frame.data, dtype=np.int16)
            
            # Convertir en WAV bytes pour le STT
            import wave
            import io
            
            wav_buffer = io.BytesIO()
            with wave.open(wav_buffer, 'wb') as wav_file:
                wav_file.setnchannels(1)  # Mono
                wav_file.setsampwidth(2)  # 16-bit
                wav_file.setframerate(audio_frame.sample_rate)
                wav_file.writeframes(audio_data.tobytes())
            
            wav_data = wav_buffer.getvalue()
            
            # Transcription
            transcription = await self.custom_stt.transcribe(wav_data)
            
            if transcription and len(transcription.strip()) > 2:
                self.transcriptions_made += 1
                return transcription
            
            return None
            
        except Exception as e:
            logger.error(f"âŒ Erreur traitement audio: {e}")
            return None
    
    async def generate_coaching_response(self, user_text: str) -> Optional[bytes]:
        """GÃ©nÃ¨re une rÃ©ponse de coaching et la convertit en audio"""
        try:
            # GÃ©nÃ©rer la rÃ©ponse textuelle
            response_text = await self.custom_llm.generate_response(user_text)
            
            if response_text:
                self.responses_generated += 1
                
                # Convertir en audio
                audio_data = await self.custom_tts.synthesize(response_text)
                return audio_data
            
            return None
            
        except Exception as e:
            logger.error(f"âŒ Erreur gÃ©nÃ©ration rÃ©ponse: {e}")
            return None
    
    def get_performance_stats(self) -> dict:
        """Retourne les statistiques de performance"""
        return {
            "audio_frames_processed": self.audio_frames_processed,
            "transcriptions_made": self.transcriptions_made,
            "responses_generated": self.responses_generated,
            "success_rate": (self.transcriptions_made / max(1, self.audio_frames_processed)) * 100
        }

@function_tool
async def get_coaching_tips(
    context: RunContext,
    topic: str = "diction gÃ©nÃ©rale",
):
    """Fournit des conseils de coaching vocal sur un sujet spÃ©cifique"""
    
    tips = {
        "diction": [
            "Articulez chaque syllabe distinctement",
            "Ouvrez bien la bouche pour les voyelles",
            "Travaillez les consonnes finales"
        ],
        "respiration": [
            "Respirez avec le diaphragme, pas la poitrine",
            "Prenez des pauses naturelles entre les phrases",
            "ContrÃ´lez votre dÃ©bit de parole"
        ],
        "intonation": [
            "Variez votre mÃ©lodie vocale",
            "Montez en fin de question",
            "Descendez en fin d'affirmation"
        ]
    }
    
    topic_key = topic.lower()
    if any(key in topic_key for key in tips.keys()):
        for key in tips.keys():
            if key in topic_key:
                return {"tips": tips[key], "topic": topic}
    
    return {"tips": tips["diction"], "topic": "diction gÃ©nÃ©rale"}

async def entrypoint(room_name: str, participant_identity: str, livekit_token: str):
    """Point d'entrÃ©e principal de l'agent"""
    logger.info(f"ğŸ¯ DÃ©marrage de l'agent de coaching vocal pour room: {room_name}")
    
    # CrÃ©er l'agent de coaching vocal
    agent = CoachingVocalAgent()
    
    # CrÃ©er la session avec VAD pour la dÃ©tection de voix
    # Utiliser webrtcvad
    vad = webrtcvad.Vad(3) # Mode 3 est le plus agressif
    session = AgentSession(
        vad=vad,  # DÃ©tection d'activitÃ© vocale avec webrtcvad
        # Nos services personnalisÃ©s seront utilisÃ©s dans l'agent
    )
    
    # DÃ©marrer la session
    # Utiliser les arguments pour se connecter Ã  la room
    await session.start(
        agent=agent,
        room_url=os.getenv('LIVEKIT_URL', 'ws://livekit:7880'), # Utiliser l'URL interne par dÃ©faut
        token=livekit_token,
        participant_identity=participant_identity,
        room_name=room_name
    )
    
    logger.info(f"âœ… Agent de coaching vocal dÃ©marrÃ© avec succÃ¨s pour room: {room_name}")
    
    # Maintenir la session active
    try:
        while True:
            await asyncio.sleep(1)
            
            # Log des statistiques pÃ©riodiquement
            if agent.audio_frames_processed % 100 == 0 and agent.audio_frames_processed > 0:
                stats = agent.get_performance_stats()
                logger.info(f"ğŸ“Š Stats: {stats}")
                
    except KeyboardInterrupt:
        logger.info("ğŸ›‘ ArrÃªt de l'agent demandÃ©")
    except Exception as e:
        logger.error(f"âŒ Erreur dans la boucle principale: {e}")
    finally:
        logger.info("ğŸ”Œ DÃ©connexion de l'agent")

if __name__ == "__main__":
    # Lire les informations de connexion depuis les variables d'environnement
    room_name = os.getenv("ROOM_NAME")
    participant_identity = os.getenv("PARTICIPANT_IDENTITY")
    livekit_token = os.getenv("LIVEKIT_TOKEN")

    if not all([room_name, participant_identity, livekit_token]):
        logger.error("âŒ Variables d'environnement ROOM_NAME, PARTICIPANT_IDENTITY et LIVEKIT_TOKEN doivent Ãªtre dÃ©finies.")
        exit(1)

    logger.info(f"ğŸš€ Lancement de l'agent LiveKit moderne pour room: {room_name}")
    
    # ExÃ©cuter le point d'entrÃ©e avec les informations de connexion
    asyncio.run(entrypoint(room_name, participant_identity, livekit_token))