// Autogenerated from Pigeon (v19.0.2), do not edit directly.
// See also: https://pub.dev/packages/pigeon
// ignore_for_file: public_member_api_docs, non_constant_identifier_names, avoid_as, unused_import, unnecessary_parenthesis, prefer_null_aware_operators, omit_local_variable_types, unused_shown_name, unnecessary_import, no_leading_underscores_for_local_identifiers

import 'dart:async';
import 'dart:typed_data' show Float64List, Int32List, Int64List, Uint8List;

import 'package:flutter/foundation.dart' show ReadBuffer, WriteBuffer;
import 'package:flutter/services.dart';

PlatformException _createConnectionError(String channelName) {
  return PlatformException(
    code: 'channel-error',
    message: 'Unable to establish connection on channel: "$channelName".',
  );
}

class PronunciationAssessmentResult {
  PronunciationAssessmentResult({
    this.accuracyScore,
    this.pronunciationScore,
    this.completenessScore,
    this.fluencyScore,
    this.words,
  });

  double? accuracyScore;

  double? pronunciationScore;

  double? completenessScore;

  double? fluencyScore;

  List<WordAssessmentResult?>? words;

  Object encode() {
    return <Object?>[
      accuracyScore,
      pronunciationScore,
      completenessScore,
      fluencyScore,
      words,
    ];
  }

  static PronunciationAssessmentResult decode(Object result) {
    result as List<Object?>;
    return PronunciationAssessmentResult(
      accuracyScore: result[0] as double?,
      pronunciationScore: result[1] as double?,
      completenessScore: result[2] as double?,
      fluencyScore: result[3] as double?,
      words: (result[4] as List<Object?>?)?.cast<WordAssessmentResult?>(),
    );
  }
}

class WordAssessmentResult {
  WordAssessmentResult({
    this.word,
    this.accuracyScore,
    this.errorType,
  });

  String? word;

  double? accuracyScore;

  String? errorType;

  Object encode() {
    return <Object?>[
      word,
      accuracyScore,
      errorType,
    ];
  }

  static WordAssessmentResult decode(Object result) {
    result as List<Object?>;
    return WordAssessmentResult(
      word: result[0] as String?,
      accuracyScore: result[1] as double?,
      errorType: result[2] as String?,
    );
  }
}

class _AzureSpeechApiCodec extends StandardMessageCodec {
  const _AzureSpeechApiCodec();
  @override
  void writeValue(WriteBuffer buffer, Object? value) {
    if (value is PronunciationAssessmentResult) {
      buffer.putUint8(128);
      writeValue(buffer, value.encode());
    } else if (value is WordAssessmentResult) {
      buffer.putUint8(129);
      writeValue(buffer, value.encode());
    } else {
      super.writeValue(buffer, value);
    }
  }

  @override
  Object? readValueOfType(int type, ReadBuffer buffer) {
    switch (type) {
      case 128: 
        return PronunciationAssessmentResult.decode(readValue(buffer)!);
      case 129: 
        return WordAssessmentResult.decode(readValue(buffer)!);
      default:
        return super.readValueOfType(type, buffer);
    }
  }
}

class AzureSpeechApi {
  /// Constructor for [AzureSpeechApi].  The [binaryMessenger] named argument is
  /// available for dependency injection.  If it is left null, the default
  /// BinaryMessenger will be used which routes to the host platform.
  AzureSpeechApi({BinaryMessenger? binaryMessenger, String messageChannelSuffix = ''})
      : __pigeon_binaryMessenger = binaryMessenger,
        __pigeon_messageChannelSuffix = messageChannelSuffix.isNotEmpty ? '.$messageChannelSuffix' : '';
  final BinaryMessenger? __pigeon_binaryMessenger;

  static const MessageCodec<Object?> pigeonChannelCodec = _AzureSpeechApiCodec();

  final String __pigeon_messageChannelSuffix;

  /// Initialise le SDK Azure Speech avec les clés fournies.
  Future<void> initialize(String subscriptionKey, String region) async {
    final String __pigeon_channelName = 'dev.flutter.pigeon.eloquence_flutter.AzureSpeechApi.initialize$__pigeon_messageChannelSuffix';
    final BasicMessageChannel<Object?> __pigeon_channel = BasicMessageChannel<Object?>(
      __pigeon_channelName,
      pigeonChannelCodec,
      binaryMessenger: __pigeon_binaryMessenger,
    );
    final List<Object?>? __pigeon_replyList =
        await __pigeon_channel.send(<Object?>[subscriptionKey, region]) as List<Object?>?;
    if (__pigeon_replyList == null) {
      throw _createConnectionError(__pigeon_channelName);
    } else if (__pigeon_replyList.length > 1) {
      throw PlatformException(
        code: __pigeon_replyList[0]! as String,
        message: __pigeon_replyList[1] as String?,
        details: __pigeon_replyList[2],
      );
    } else {
      return;
    }
  }

  /// Démarre l'évaluation de la prononciation pour le texte de référence donné.
  /// Retourne le résultat de l'évaluation ou null si aucun discours n'est reconnu.
  /// Lance une exception en cas d'erreur de configuration ou de reconnaissance.
  Future<PronunciationAssessmentResult?> startPronunciationAssessment(String referenceText, String language) async {
    final String __pigeon_channelName = 'dev.flutter.pigeon.eloquence_flutter.AzureSpeechApi.startPronunciationAssessment$__pigeon_messageChannelSuffix';
    final BasicMessageChannel<Object?> __pigeon_channel = BasicMessageChannel<Object?>(
      __pigeon_channelName,
      pigeonChannelCodec,
      binaryMessenger: __pigeon_binaryMessenger,
    );
    final List<Object?>? __pigeon_replyList =
        await __pigeon_channel.send(<Object?>[referenceText, language]) as List<Object?>?;
    if (__pigeon_replyList == null) {
      throw _createConnectionError(__pigeon_channelName);
    } else if (__pigeon_replyList.length > 1) {
      throw PlatformException(
        code: __pigeon_replyList[0]! as String,
        message: __pigeon_replyList[1] as String?,
        details: __pigeon_replyList[2],
      );
    } else {
      return (__pigeon_replyList[0] as PronunciationAssessmentResult?);
    }
  }

  /// Arrête toute reconnaissance vocale en cours.
  Future<void> stopRecognition() async {
    final String __pigeon_channelName = 'dev.flutter.pigeon.eloquence_flutter.AzureSpeechApi.stopRecognition$__pigeon_messageChannelSuffix';
    final BasicMessageChannel<Object?> __pigeon_channel = BasicMessageChannel<Object?>(
      __pigeon_channelName,
      pigeonChannelCodec,
      binaryMessenger: __pigeon_binaryMessenger,
    );
    final List<Object?>? __pigeon_replyList =
        await __pigeon_channel.send(null) as List<Object?>?;
    if (__pigeon_replyList == null) {
      throw _createConnectionError(__pigeon_channelName);
    } else if (__pigeon_replyList.length > 1) {
      throw PlatformException(
        code: __pigeon_replyList[0]! as String,
        message: __pigeon_replyList[1] as String?,
        details: __pigeon_replyList[2],
      );
    } else {
      return;
    }
  }

  /// Démarre la reconnaissance vocale continue simple (sans évaluation de prononciation).
  /// Les résultats (partiels, finaux) et erreurs sont envoyés via l'EventChannel.
  Future<void> startContinuousRecognition(String language) async {
    final String __pigeon_channelName = 'dev.flutter.pigeon.eloquence_flutter.AzureSpeechApi.startContinuousRecognition$__pigeon_messageChannelSuffix';
    final BasicMessageChannel<Object?> __pigeon_channel = BasicMessageChannel<Object?>(
      __pigeon_channelName,
      pigeonChannelCodec,
      binaryMessenger: __pigeon_binaryMessenger,
    );
    final List<Object?>? __pigeon_replyList =
        await __pigeon_channel.send(<Object?>[language]) as List<Object?>?;
    if (__pigeon_replyList == null) {
      throw _createConnectionError(__pigeon_channelName);
    } else if (__pigeon_replyList.length > 1) {
      throw PlatformException(
        code: __pigeon_replyList[0]! as String,
        message: __pigeon_replyList[1] as String?,
        details: __pigeon_replyList[2],
      );
    } else {
      return;
    }
  }
}
