import 'dart:async';
import 'dart:convert';
import 'dart:io';
import 'dart:math';

import 'package:flutter/material.dart';
import 'package:flutter/services.dart';
import 'package:go_router/go_router.dart'; // Ajouter l'import GoRouter
// ignore: depend_on_referenced_packages
import 'package:path_provider/path_provider.dart';
import 'package:supabase_flutter/supabase_flutter.dart'; // Importer Supabase

import '../../../app/routes.dart';
import '../../../domain/entities/exercise.dart';
import '../../../domain/repositories/audio_repository.dart';
import '../../../domain/repositories/exercise_repository.dart';
import '../../../services/azure/azure_speech_service.dart'; // Ajouter cet import
import '../../../services/azure/azure_tts_service.dart';
import '../../../services/openai/openai_feedback_service.dart';
import '../../../services/service_locator.dart';
import '../../../app/theme.dart'; // Importer AppTheme
import '../../widgets/microphone_button.dart'; // Importer le bouton micro
import '../../widgets/visual_effects/info_modal.dart'; // Importer la modale info
import '../../../domain/entities/azure_pronunciation_assessment.dart'; // Importer les nouveaux mod√®les
// Importer l'√©cran des r√©sultats
import '../../../core/utils/console_logger.dart'; // Pour les logs

// IMPORTANT: Les fonctions _saveWordResult et _setDatabaseSafeMode pr√©parent les donn√©es
// et indiquent quelle action MCP doit √™tre ex√©cut√©e par l'environnement externe.
// L'appel r√©el <use_mcp_tool> n'est PAS effectu√© directement dans ce code Dart.

class SyllabicPrecisionExerciseScreen extends StatefulWidget {
  final Exercise exercise;

  const SyllabicPrecisionExerciseScreen({
    super.key,
    required this.exercise,
  });

  static const String routeName = '/exercise/syllabic_precision'; // Cha√Æne constante originale

  @override
  _SyllabicPrecisionExerciseScreenState createState() =>
      _SyllabicPrecisionExerciseScreenState();
}

class _SyllabicPrecisionExerciseScreenState
    extends State<SyllabicPrecisionExerciseScreen> {
  // √âtats
  Map<String, List<String>> _lexique = {};
  String _currentWord = "";
  List<String> _currentSyllables = [];
  bool _isLoading = true;
  bool _isRecording = false;
  int _currentWordIndex = 0;
  List<String> _wordList = [];
  final List<Map<String, dynamic>> _sessionResults = []; // Pour stocker les r√©sultats de chaque mot
  String _openAiFeedback = ''; // Pour stocker le feedback final de l'IA

  // Services
  late final AudioRepository _audioRepository;
  late final AzureTtsService _ttsService;
  late final ExerciseRepository _exerciseRepository;
  late final OpenAIFeedbackService _openAIFeedbackService;
  late final AzureSpeechService _azureSpeechService; // Ajouter le service Azure Speech

  // Platform Channels
  // static const _methodChannelName = "com.eloquence.app/azure_speech"; // Supprim√©
  static const _eventChannelName = "com.eloquence.app/azure_speech_events"; // Garder pour les √©v√©nements
  // final MethodChannel _methodChannel = const MethodChannel(_methodChannelName); // Supprim√©
  final EventChannel _eventChannel = const EventChannel(_eventChannelName); // Garder pour les √©v√©nements
  StreamSubscription? _eventSubscription;
  StreamSubscription<Uint8List>? _audioStreamSubscription;

  // √âtat pour le traitement
  bool _isProcessing = false; // Indique si l'enregistrement est en cours d'analyse
  bool _wordProcessed = false; // Verrou pour s'assurer qu'un seul r√©sultat final est trait√© par mot/enregistrement
  bool _resultReceived = false; // Indique si le r√©sultat final a √©t√© re√ßu pour le mot actuel
  String? _currentlyProcessingWord; // Stocke le mot dont on attend le r√©sultat
  Timer? _processingTimeoutTimer;

  @override
  void initState() {
    super.initState();
    _initServices();
    _setupAzureChannelListener();
    _loadExerciseData();
  }

  @override
  void dispose() {
    _eventSubscription?.cancel();
    _audioStreamSubscription?.cancel();
    _processingTimeoutTimer?.cancel(); // Annuler le timer ici est toujours important
    _setDatabaseSafeMode(false); // Mettre enable_unsafe_mode √† false pour revenir en SAFE
    super.dispose();
  }

  void _initServices() {
    _audioRepository = serviceLocator<AudioRepository>();
    _ttsService = serviceLocator<AzureTtsService>();
    _exerciseRepository = serviceLocator<ExerciseRepository>();
    _openAIFeedbackService = serviceLocator<OpenAIFeedbackService>();
    _azureSpeechService = serviceLocator<AzureSpeechService>(); // R√©cup√©rer le service
  }

  void _setupAzureChannelListener() {
     _eventSubscription = _eventChannel.receiveBroadcastStream().listen(
      (event) { // Version originale sans async/await
        if (event is! Map) return;
        final Map<dynamic, dynamic> eventMap = event;
        final String? type = eventMap['type'] as String?;
        final dynamic payload = eventMap['payload'];

         print("[Flutter Event Listener] Received event: type=$type, payload=$payload");

         // V√©rifier le nouveau verrou avant de traiter le r√©sultat final
         if (type == 'finalResult' && payload is Map && !_wordProcessed) { // Assurez-vous que 'finalResult' correspond √† ce qui est envoy√© par Kotlin
           // ANNULER le timer ici car nous avons re√ßu un r√©sultat final valide.
           _processingTimeoutTimer?.cancel();
           _processingTimeoutTimer = null;
           print("[Flutter Event Listener] Timeout timer cancelled on finalResult event reception.");

           // Ajouter un try-catch pour le traitement du payload
           try {
             _wordProcessed = true; // Activer le verrou pour ce mot
             final Map<dynamic, dynamic> finalPayload = payload;
             final dynamic pronunciationResultJsonInput = finalPayload['pronunciationResult'];

             print("[Flutter Event Listener] Pronunciation Result JSON: $pronunciationResultJsonInput");

             // Mettre √† jour l'√©tat pour arr√™ter l'indicateur de traitement
             if (mounted) {
               setState(() { _isProcessing = false; });
             } else {
               print("[Flutter Event Listener] Widget unmounted before processing final result. Aborting.");
               return; // Ne rien faire si le widget n'est plus mont√©
             }

             // Parser le r√©sultat en utilisant le mod√®le typ√©
             final AzurePronunciationAssessmentResult? parsedResult =
                 AzurePronunciationAssessmentResult.tryParse(pronunciationResultJsonInput);

             final evaluationResult = _performSyllabicAnalysis(
                 parsedResult, _currentWord, _currentSyllables); // Passer l'objet pars√©
             print("R√©sultat de l'analyse pour '$_currentWord': $evaluationResult");

             // Passer l'objet pars√© √† _saveWordResult via la map retourn√©e par _performSyllabicAnalysis
             _saveWordResult(evaluationResult); // Pas de await ici
             _resultReceived = true; // Marquer que le r√©sultat est arriv√©

             // Arr√™ter la reconnaissance native car nous avons un r√©sultat final valide
             print("[Flutter Event Listener] R√©sultat final trait√©, arr√™t de la reconnaissance native via service...");
             _azureSpeechService.stopRecognition().catchError((e) { // Utiliser le service
               print("[Flutter Event Listener] Erreur lors de l'appel stopRecognition (via service) apr√®s r√©sultat final: $e");
             });

             // Le r√©sultat final a √©t√© re√ßu et trait√© avec succ√®s.
             // Programmer le passage au mot suivant apr√®s la fin du frame actuel.
             if (mounted) {
                 print("[Flutter Event Listener] Traitement du r√©sultat final r√©ussi, programmation du passage au mot suivant.");
                 WidgetsBinding.instance.addPostFrameCallback((_) {
                   // V√©rifier √† nouveau si le widget est mont√© dans le callback
                   if (mounted) {
                     try {
                       _nextWord();
                       _resultReceived = false; // R√©initialiser pour le prochain mot
                     } catch (e, s) {
                       print("üî¥ Erreur lors de l'ex√©cution diff√©r√©e de _nextWord: $e\n$s");
                       // G√©rer l'erreur si n√©cessaire (ex: afficher un message)
                     }
                   } else {
                      print("[Flutter Event Listener] Widget d√©mont√© avant l'ex√©cution diff√©r√©e de _nextWord.");
                   }
                 });
             } else {
                 print("[Flutter Event Listener] Widget d√©mont√© apr√®s traitement, impossible de programmer _nextWord.");
             }
             // _wordProcessed sera r√©initialis√© dans _startRecording pour le prochain mot.
           } catch (e, s) {
             // Capturer et logger toute erreur pendant le traitement du payload
             print("üî¥ [Flutter Event Listener] Erreur lors du traitement du payload 'final': $e");
             print(s); // Afficher la stack trace
             _wordProcessed = false; // R√©initialiser le verrou en cas d'erreur de traitement
             _resultReceived = false; // R√©initialiser aussi
             _currentlyProcessingWord = null; // R√©initialiser le mot attendu
             if (mounted) {
               setState(() { _isProcessing = false; }); // Assurer que l'indicateur s'arr√™te
               ScaffoldMessenger.of(context).showSnackBar(
                 SnackBar(content: Text('Erreur traitement r√©sultat: ${e.toString()}')),
               );
             }
           }

          } else if (type == 'final' && _wordProcessed) {
             print("[Flutter Event Listener] Ignored duplicate final event for this word.");
         } else if (type == 'error' && payload is Map) {
           // ANNULER le timer ici car une erreur est survenue.
           _processingTimeoutTimer?.cancel();
           _processingTimeoutTimer = null;
           print("[Flutter Event Listener] Timeout timer cancelled on error event reception.");
           _wordProcessed = true; // Marquer comme trait√© pour que le timer ne fasse rien
           _resultReceived = false; // R√©initialiser aussi
           _currentlyProcessingWord = null; // R√©initialiser le mot attendu
           final Map<dynamic, dynamic> errorPayload = payload;
           // Extraire les informations d'erreur du payload
           final String? errorCode = errorPayload['code'] as String?;
           final String? errorMessage = errorPayload['message'] as String?;
           // final dynamic errorDetails = errorPayload['details']; // Non utilis√© pour l'instant

           print("[Flutter Event Listener] Error: $errorCode, message=$errorMessage");

          if (mounted) {
            setState(() {
              _isRecording = false; // Arr√™ter l'enregistrement visuellement
              _isProcessing = false; // Arr√™ter l'indicateur de traitement
            });
            ScaffoldMessenger.of(context).showSnackBar(
              SnackBar(content: Text('Erreur Azure: ${errorMessage ?? "Erreur inconnue"}')), // Utiliser errorMessage ici
            );
          }
        }
      },
      onError: (error) {
       print("[Flutter Event Listener] Error receiving event: $error");
       // ANNULER le timer ici car une erreur est survenue dans le stream.
       _processingTimeoutTimer?.cancel();
       _processingTimeoutTimer = null;
       print("[Flutter Event Listener] Timeout timer cancelled on stream error.");
       _wordProcessed = true; // Marquer comme trait√© pour que le timer ne fasse rien
       _resultReceived = false; // R√©initialiser aussi
       _currentlyProcessingWord = null; // R√©initialiser
       if (mounted) {
         setState(() {
           _isRecording = false; // Arr√™ter l'enregistrement visuellement
           _isProcessing = false; // Arr√™ter l'indicateur de traitement
         });
         ScaffoldMessenger.of(context).showSnackBar(
            SnackBar(content: Text('Erreur de communication Azure: $error')),
          );
        }
      },
      onDone: () {
       print("[Flutter Event Listener] Event stream closed.");
       // Annuler le timer si le stream se ferme est toujours une bonne id√©e
       _processingTimeoutTimer?.cancel();
       _wordProcessed = true; // Marquer comme trait√©
       _resultReceived = false; // R√©initialiser aussi
       _currentlyProcessingWord = null; // R√©initialiser
       if (mounted) {
         setState(() {
           _isRecording = false; // Assurer que l'enregistrement est arr√™t√© visuellement
           _isProcessing = false; // Assurer que l'indicateur est arr√™t√©
         });
        }
      }
    );
    print("[Flutter] Azure Event Channel Listener setup complete.");
  }

  Future<void> _loadExerciseData() async {
    if (mounted) {
      setState(() { _isLoading = true; });
    }
    try {
      final List<Map<String, dynamic>> generatedData = await _openAIFeedbackService.generateSyllabicWords(
        exerciseLevel: _difficultyToString(widget.exercise.difficulty), // Appel de la m√©thode d√©finie
        wordCount: 5,
      );

      _wordList = [];
      _lexique = {};
      for (var item in generatedData) {
        final String word = item['word'];
        final List<String> syllables = List<String>.from(item['syllables']);
        if (word.isNotEmpty && syllables.isNotEmpty) {
          _wordList.add(word);
          _lexique[word] = syllables;
        }
      }

      print("[Flutter OpenAI] Nombre de mots g√©n√©r√©s: ${_wordList.length}");
      if (_wordList.isNotEmpty) {
        print("[Flutter OpenAI] Premier mot: ${_wordList.first}");
        print("[Flutter OpenAI] Syllabes pour le premier mot: ${_lexique[_wordList.first]}");
        _setWord(0);
      } else {
        print("Erreur: Aucun mot valide g√©n√©r√© par OpenAI.");
        if (mounted) {
           ScaffoldMessenger.of(context).showSnackBar(
             const SnackBar(content: Text('Erreur: Aucun mot g√©n√©r√© pour l\'exercice.')),
           );
        }
      }
    } catch (e) {
      print("Erreur lors de la g√©n√©ration des mots via OpenAI: $e");
      if (mounted) {
         ScaffoldMessenger.of(context).showSnackBar(
           SnackBar(content: Text('Erreur g√©n√©ration mots: ${e.toString()}')),
         );
      }
    } finally {
      if (mounted) {
        setState(() { _isLoading = false; });
      }
    }
  }

  void _setWord(int index) {
    if (_wordList.isNotEmpty && index >= 0 && index < _wordList.length) {
      _currentWordIndex = index;
       _currentWord = _wordList[index];
       _currentSyllables = _lexique[_currentWord] ?? [];
       print("Setting word: $_currentWord, Syllables: $_currentSyllables");
       // _wordProcessed et _resultReceived seront r√©initialis√©s dans _startRecording
       if (mounted) {
         setState(() {});
       }
     } else if (_wordList.isNotEmpty) {
       print("Index de mot invalide: $index (Taille liste: ${_wordList.length})");
       _setWord(0);
    } else {
       print("Impossible de d√©finir un mot, la liste est vide.");
       _currentWord = "";
       _currentSyllables = [];
       if (mounted) setState(() {});
    }
  }

  void _nextWord() {
    if (_wordList.isEmpty) {
       print("Impossible de passer au mot suivant, liste vide.");
       if (mounted) Navigator.pop(context);
       return;
    }

    if (_currentWordIndex < _wordList.length - 1) {
      _setWord(_currentWordIndex + 1);
    } else {
      print("Fin de l'exercice de pr√©cision syllabique. Traitement des r√©sultats finaux...");
      _completeExercise(); // Appeler la fonction de compl√©tion
    }
  }

  Future<void> _startRecording() async {
    if (_isRecording || _isProcessing || _currentWord.isEmpty || _currentSyllables.isEmpty) {
       if (_currentSyllables.isEmpty && _currentWord.isNotEmpty) {
          print("Avertissement: Tentative d'enregistrement pour un mot sans syllabes ('$_currentWord'). Passage au suivant.");
          _nextWord();
        }
         return;
      }
     _wordProcessed = false; // R√©initialiser le verrou pour le nouvel enregistrement
     _resultReceived = false; // R√©initialiser l'indicateur de r√©ception de r√©sultat
     _currentlyProcessingWord = _currentWord; // D√©finir le mot attendu pour ce nouvel enregistrement

      try {
        print("[Flutter] Appel startRecognition via AzureSpeechService avec referenceText: $_currentWord");
        // Utiliser le service AzureSpeechService au lieu du MethodChannel direct
        await _azureSpeechService.startRecognition(referenceText: _currentWord);

      final audioStream = await _audioRepository.startRecordingStream();
      if (mounted) {
        setState(() { _isRecording = true; });
      }
      print("[Flutter] Enregistrement audio stream d√©marr√© pour: $_currentWord");

      // D√©marrer le timer de timeout global pour ce mot
      _processingTimeoutTimer?.cancel(); // Annuler tout timer pr√©c√©dent
      print("[Flutter _startRecording] D√©marrage du timer de timeout global (30s) pour '$_currentWord'.");
      _processingTimeoutTimer = Timer(const Duration(seconds: 30), () {
        // V√©rification cruciale : le mot a-t-il d√©j√† √©t√© trait√© (r√©sultat ou erreur re√ßu) ?
        if (_wordProcessed) {
           print("üî¥ [Flutter Timeout] Callback ex√©cut√© pour '$_currentWord', mais mot d√©j√† trait√©. Ignor√©.");
           return;
        }
        // Si le mot n'a PAS √©t√© trait√©, alors c'est un vrai timeout.
        print("üî¥ [Flutter Timeout] Timeout global pour '$_currentWord'. Arr√™t forc√©.");
        _wordProcessed = true; // Marquer comme trait√© pour √©viter double traitement

        if (mounted && (_isRecording || _isProcessing)) { // V√©rifier si toujours actif
          print("üî¥ [Flutter Timeout] Conditions remplies: mounted=$mounted, isRecording=$_isRecording, isProcessing=$_isProcessing, processingWord=$_currentlyProcessingWord");
          setState(() {
             _isRecording = false;
            _isProcessing = false;
            _resultReceived = false; // Assurer la r√©initialisation
            _currentlyProcessingWord = null;
          });
          ScaffoldMessenger.of(context).showSnackBar(
            const SnackBar(content: Text('Timeout: Aucun r√©sultat re√ßu dans le temps imparti.')),
          );
          // Forcer l'arr√™t de la reconnaissance native
          _azureSpeechService.stopRecognition().catchError((e) => print("üî¥ Erreur stopRecognition (timeout global): $e"));
          // Peut-√™tre appeler _nextWord() ici pour d√©bloquer l'UI ? Ou afficher un message ?
          // Pour l'instant, on arr√™te juste.
        } else {
           print("üî¥ [Flutter Timeout] Conditions NON remplies ou widget d√©mont√©.");
        }
      });

      // Pas de d√©tection de silence ici

      _audioStreamSubscription?.cancel();
      _audioStreamSubscription = audioStream.listen(
        (audioChunk) {
          // L'envoi de chunks n'est plus n√©cessaire avec Pigeon/Repository
          // print("[Flutter] Audio chunk received, size: ${audioChunk.length}. Sending handled natively.");
        },
        onError: (error) {
          print("[Flutter] Erreur du stream audio: $error");
          if (mounted) {
            setState(() { _isRecording = false; });
            ScaffoldMessenger.of(context).showSnackBar(
              SnackBar(content: Text('Erreur enregistrement: $error')),
            );
          }
          // Arr√™ter via le service en cas d'erreur du stream audio
          _azureSpeechService.stopRecognition().catchError((e) => print("Erreur stopRecognition (stream error via service): $e"));
        },
        onDone: () {
          print("[Flutter] Stream audio termin√©.");
        },
        cancelOnError: true,
      );

    } catch (e) {
      print("[Flutter] Erreur au d√©marrage de l'enregistrement/reconnaissance: $e");
      if (mounted) {
        setState(() { _isRecording = false; });
        ScaffoldMessenger.of(context).showSnackBar(
          SnackBar(content: Text('Erreur d√©marrage: ${e.toString()}')),
        );
      }
    }
  }

  // Fonction _stopRecording r√©vis√©e pour g√©rer le changement de mot
  Future<void> _stopRecording() async {
    // Garde pour √©viter les appels multiples si d√©j√† arr√™t√© ou pas en enregistrement
    if (!_isRecording && !_isProcessing) {
      print("[Flutter _stopRecording] Ignor√©: Ni en enregistrement ni en traitement.");
      return;
    }

    // _processingTimeoutTimer?.cancel(); // Annuler le timer global ici n'est plus n√©cessaire, le listener s'en charge

    // bool shouldStartProcessing = false; // Supprimer la logique du timer secondaire
    if (mounted) {
      // Mettre √† jour l'√©tat imm√©diatement pour arr√™ter l'indicateur d'enregistrement
      // et d√©marrer l'indicateur de traitement SEULEMENT si le mot n'a pas d√©j√† √©t√© trait√©
      setState(() {
        _isRecording = false; // Toujours arr√™ter l'enregistrement visuellement
        if (!_wordProcessed) {
          _isProcessing = true;
          // shouldStartProcessing = true; // Marquer pour d√©marrer le timer plus tard // Supprim√©
        } else {
          // Si le mot a d√©j√† √©t√© trait√© (par l'event listener), s'assurer que _isProcessing est false
          _isProcessing = false;
          print("[Flutter _stopRecording] Mot d√©j√† trait√©, _isProcessing mis √† false.");
        }
      });
    }

    // Supprimer toute la logique de d√©marrage du timer secondaire dans _stopRecording

    // Tenter d'arr√™ter les streams et la reconnaissance native
    try {
      await _audioStreamSubscription?.cancel();
      _audioStreamSubscription = null;
      print("[Flutter] Abonnement au stream audio annul√©.");

      await _audioRepository.stopRecordingStream();
      print("[Flutter] Enregistrement audio stream arr√™t√©.");

      // Appeler stopRecognition ici via le service.
      print("[Flutter _stopRecording] Appel stopRecognition via AzureSpeechService...");
      await _azureSpeechService.stopRecognition();
      print("[Flutter] Appel stopRecognition (via service) termin√©.");

     } catch (e) {
       print("[Flutter] Erreur lors de l'arr√™t de l'enregistrement/reconnaissance: $e");
      _processingTimeoutTimer?.cancel(); // Assurer l'annulation du timer en cas d'erreur
      if (mounted) {
        setState(() {
          // Assurer que les √©tats sont r√©initialis√©s en cas d'erreur
          _isRecording = false;
          _isProcessing = false;
          _wordProcessed = false;
          _resultReceived = false;
          _currentlyProcessingWord = null;
        });
        ScaffoldMessenger.of(context).showSnackBar(
          SnackBar(content: Text('Erreur arr√™t: ${e.toString()}')),
        );
      }
    }
  }

   // Modifi√© pour accepter AzurePronunciationAssessmentResult?
   Map<String, dynamic> _performSyllabicAnalysis(AzurePronunciationAssessmentResult? assessmentResult, String expectedWord, List<String> expectedSyllables) {
     print("[Flutter] Analyse pour '$expectedWord' (${expectedSyllables.join('-')}) avec objet: ${assessmentResult != null}");

     // Initialiser les variables avec des valeurs par d√©faut
     String transcription = "Analyse √©chou√©e";
     double globalScore = 0.0;
     String clarityFeedback = "Erreur lors de l'analyse du r√©sultat.";
     String fluencyFeedback = "";
     Map<String, double> syllableScores = {};
     List<String> problematicSyllables = [];
     // rawPronunciationResult contiendra l'objet pars√© ou null
     AzurePronunciationAssessmentResult? rawPronunciationResult = assessmentResult;
     bool scoresAssignedDirectly = false;

     Map<String, dynamic> defaultResult = {
      'transcription': transcription,
      'expectedWord': expectedWord,
      'expectedSyllables': expectedSyllables,
      'syllableScores': syllableScores,
      'problematicSyllables': problematicSyllables,
      'globalScore': globalScore.round(),
       'clarityFeedback': clarityFeedback,
       'fluencyFeedback': fluencyFeedback,
       'rawPronunciationResult': rawPronunciationResult // Stocker l'objet pars√© ici
     };

     if (expectedSyllables.isEmpty) {
       print("Avertissement: Aucune syllabe attendue pour le mot '$expectedWord'. Analyse impossible.");
        return defaultResult..['clarityFeedback'] = "Aucune syllabe d√©finie pour ce mot.";
     }

     // Utiliser l'objet pars√© directement
     if (assessmentResult == null) {
       print("Erreur: R√©sultat d'√©valuation invalide ou non parsable re√ßu.");
       return defaultResult..['clarityFeedback'] = "Erreur: R√©sultat d'√©valuation invalide.";
     }

     try {
       // Acc√©der aux donn√©es via le mod√®le typ√©
       final nBest = assessmentResult.nBest.firstOrNull;
       transcription = nBest?.display ?? "N/A";

       // Utiliser PronScore pour le score global si disponible, sinon AccuracyScore
       globalScore = nBest?.pronunciationAssessment?.pronScore ??
                     nBest?.pronunciationAssessment?.accuracyScore ?? 0.0;

       final double accuracyScore = nBest?.pronunciationAssessment?.accuracyScore ?? 0.0;
       final double fluencyScore = nBest?.pronunciationAssessment?.fluencyScore ?? 0.0;
       final double completenessScore = nBest?.pronunciationAssessment?.completenessScore ?? 0.0;

       clarityFeedback = "Pr√©cision: ${accuracyScore.toStringAsFixed(0)}%, Compl√©tude: ${completenessScore.toStringAsFixed(0)}%.";
       fluencyFeedback = "Fluidit√©: ${fluencyScore.toStringAsFixed(0)}%.";

       // --- Logique d'attribution des scores aux syllabes V3 (utilisant le mod√®le) ---
       double wordScoreForSyllablesFallback = 0.0;
       bool wordFound = false;
       final List<WordResult>? azureWords = nBest?.words;

       if (azureWords != null) {
         for (final wordData in azureWords) {
           if (wordData.word?.toLowerCase() == expectedWord.toLowerCase()) {
             wordFound = true;
             final List<SyllableResult> azureSyllables = wordData.syllables;
             // Tenter d'utiliser les scores des syllabes Azure si le nombre correspond
             if (azureSyllables.length == expectedSyllables.length) {
               print("Correspondance du nombre de syllabes trouv√©e (${expectedSyllables.length}). Utilisation des scores de syllabes Azure.");
               for (int i = 0; i < expectedSyllables.length; i++) {
                 final sylScore = azureSyllables[i].pronunciationAssessment?.accuracyScore ?? 0.0;
                 syllableScores[expectedSyllables[i]] = sylScore;
               }
               scoresAssignedDirectly = true;
             }
             // Si les scores de syllabes Azure ne sont pas utilisables, calculer la moyenne des phon√®mes
             if (!scoresAssignedDirectly) {
               final List<PhonemeResult> phonemes = wordData.phonemes;
               if (phonemes.isNotEmpty) {
                 double totalPhonemeScore = 0;
                 int validPhonemeCount = 0;
                 for (final phonemeData in phonemes) {
                   final phonemeScore = phonemeData.pronunciationAssessment?.accuracyScore;
                   if (phonemeScore != null) {
                     totalPhonemeScore += phonemeScore;
                     validPhonemeCount++;
                   }
                 }
                 if (validPhonemeCount > 0) {
                   wordScoreForSyllablesFallback = totalPhonemeScore / validPhonemeCount;
                   print("Mot '$expectedWord' trouv√©. Moyenne score phon√®mes: ${wordScoreForSyllablesFallback.toStringAsFixed(1)}");
                 } else {
                   wordScoreForSyllablesFallback = wordData.pronunciationAssessment?.accuracyScore ?? 0.0;
                   print("Mot '$expectedWord' trouv√©. Pas de scores phon√®mes, utilisation score mot: ${wordScoreForSyllablesFallback.toStringAsFixed(1)}");
                 }
               } else {
                 wordScoreForSyllablesFallback = wordData.pronunciationAssessment?.accuracyScore ?? 0.0;
                 print("Mot '$expectedWord' trouv√©. Liste phon√®mes vide, utilisation score mot: ${wordScoreForSyllablesFallback.toStringAsFixed(1)}");
               }
             }
             break; // Sortir de la boucle une fois le mot trouv√©
           }
         }
       }

       // Si les scores n'ont pas √©t√© assign√©s directement et/ou si le mot n'a pas √©t√© trouv√©
       if (!scoresAssignedDirectly) {
         if (!wordFound) {
           print("Avertissement: Le mot attendu '$expectedWord' n'a pas √©t√© trouv√© dans les r√©sultats Azure. Score syllabes mis √† 0.");
           wordScoreForSyllablesFallback = 0.0;
         }
         print("Assignation du score fallback $wordScoreForSyllablesFallback √† toutes les syllabes.");
         for (var syl in expectedSyllables) {
           syllableScores[syl] = wordScoreForSyllablesFallback;
         }
       }

       problematicSyllables = expectedSyllables.where((syl) => (syllableScores[syl] ?? 0.0) < 60).toList();
       // --- Fin de la logique d'attribution ---

     } catch (e) {
       print("Erreur pendant l'extraction des donn√©es du mod√®le Azure: $e");
       // R√©assigner les valeurs par d√©faut en cas d'erreur interne
       clarityFeedback = "Erreur interne lors de l'analyse des scores.";
       fluencyFeedback = "";
       globalScore = 0;
       transcription = "Analyse √©chou√©e";
       syllableScores = {};
       problematicSyllables = [];
     }

     // Retourner la map construite avec les variables
     return {
       'transcription': transcription,
       'expectedWord': expectedWord,
       'expectedSyllables': expectedSyllables,
       'syllableScores': syllableScores,
       'problematicSyllables': problematicSyllables,
       'globalScore': globalScore.round(),
       'clarityFeedback': clarityFeedback,
       'fluencyFeedback': fluencyFeedback,
       'rawPronunciationResult': rawPronunciationResult // Inclure l'objet pars√©
     };
   }

  Future<void> _playTtsDemo() async {
    if (_isLoading || _currentWord.isEmpty || _isRecording || _isProcessing) return;
    try {
      if (_currentSyllables.isNotEmpty) {
        for (String syllable in _currentSyllables) {
          await _ttsService.synthesizeAndPlay(syllable);
          await _ttsService.isPlayingStream.firstWhere((playing) => !playing);
          await Future.delayed(const Duration(milliseconds: 150));
        }
        await Future.delayed(const Duration(milliseconds: 250));
      }
      await _ttsService.synthesizeAndPlay(_currentWord);
      await _ttsService.isPlayingStream.firstWhere((playing) => !playing);
      print("Lecture de la d√©mo TTS pour: $_currentWord termin√©e.");
    } catch (e) {
      print("Erreur lors de la lecture TTS: $e");
      if (mounted) {
        ScaffoldMessenger.of(context).showSnackBar(
          SnackBar(content: Text('Erreur TTS: ${e.toString().substring(0, min(e.toString().length, 100))}...')),
        );
      }
    }
  }

  Future<void> _saveWordResult(Map<String, dynamic> evaluationResult) async {
    final userId = Supabase.instance.client.auth.currentUser?.id;
    if (userId == null) {
      print("Erreur: Utilisateur non authentifi√©, impossible de sauvegarder le r√©sultat.");
      return;
    }

    // Ajouter le r√©sultat √† la liste de session AVANT la sauvegarde
    _sessionResults.add(evaluationResult);

    // Pr√©parer les donn√©es pour l'insertion, en g√©rant les nulls potentiels
    // et en s'assurant que les JSON sont valides
    String? expectedSyllablesJson = jsonEncode(evaluationResult['expectedSyllables'] ?? []);
    String? syllableScoresJson = jsonEncode(evaluationResult['syllableScores'] ?? {});
     String? problematicSyllablesJson = jsonEncode(evaluationResult['problematicSyllables'] ?? []);
     // Encoder l'objet rawPronunciationResult en utilisant sa m√©thode toJson()
     final rawResultObject = evaluationResult['rawPronunciationResult'] as AzurePronunciationAssessmentResult?;
     String? rawResultJson = rawResultObject != null ? jsonEncode(rawResultObject.toJson()) : null; // Utiliser toJson()

     // Extraire les scores sp√©cifiques de l'objet pars√©
     final assessment = rawResultObject?.nBest.firstOrNull?.pronunciationAssessment;
     final double? accuracyScore = assessment?.accuracyScore;
     final double? fluencyScore = assessment?.fluencyScore;
     final double? completenessScore = assessment?.completenessScore;

     final Map<String, dynamic> dataToInsert = {
      'user_id': userId,
      'exercise_id': widget.exercise.id,
      'word': evaluationResult['expectedWord'] ?? 'mot_inconnu',
      'expected_syllables': expectedSyllablesJson,
      'global_score': evaluationResult['globalScore'], // Utiliser le score global calcul√©
      'accuracy_score': accuracyScore, // Score extrait
      'fluency_score': fluencyScore, // Score extrait
      'completeness_score': completenessScore, // Score extrait
      'syllable_scores': syllableScoresJson,
      'problematic_syllables': problematicSyllablesJson,
      'transcription': evaluationResult['transcription'],
      'raw_result': rawResultJson,
    };

    // √âchapper les apostrophes pour les champs texte
    String safeExerciseId = dataToInsert['exercise_id']?.replaceAll("'", "''") ?? '';
    String safeWord = dataToInsert['word']?.replaceAll("'", "''") ?? '';
    String safeTranscription = dataToInsert['transcription']?.replaceAll("'", "''") ?? '';
    // √âchapper les apostrophes dans les cha√Ænes JSON (plus s√ªr)
    String safeExpectedSyllablesJson = expectedSyllablesJson.replaceAll("'", "''");
    String safeSyllableScoresJson = syllableScoresJson.replaceAll("'", "''");
    String safeProblematicSyllablesJson = problematicSyllablesJson.replaceAll("'", "''");
    String safeRawResultJson = rawResultJson?.replaceAll("'", "''") ?? '{}';


    // Construire la requ√™te SQL INSERT avec √©chappement manuel
    final query = """
    INSERT INTO public.syllabic_precision_attempts (
      user_id, exercise_id, word, expected_syllables, global_score,
      accuracy_score, fluency_score, completeness_score, syllable_scores,
      problematic_syllables, transcription, raw_result
    ) VALUES (
      '$userId',
      '$safeExerciseId',
      '$safeWord',
      '$safeExpectedSyllablesJson'::jsonb,
      ${dataToInsert['global_score']},
      ${dataToInsert['accuracy_score'] ?? 'NULL'},
      ${dataToInsert['fluency_score'] ?? 'NULL'},
      ${dataToInsert['completeness_score'] ?? 'NULL'},
      '$safeSyllableScoresJson'::jsonb,
      '$safeProblematicSyllablesJson'::jsonb,
      '$safeTranscription',
      '$safeRawResultJson'::jsonb
    );
    """;

    print("Tentative de sauvegarde du r√©sultat pour le mot '${evaluationResult['expectedWord']}'...");
    print("Executing SQL (via MCP Tool): $query");

    // Indiquer √† l'environnement d'ex√©cuter l'outil MCP
    // L'environnement doit interpr√©ter ce log et faire l'appel <use_mcp_tool>
    print("MCP_EXECUTE_TOOL: server=github.com/alexander-zuev/supabase-mcp-server tool=execute_postgresql query=\"$query\"");

    // Simuler un succ√®s localement pour le flux de l'UI
    print("R√©sultat sauvegard√© (simulation) pour le mot '${evaluationResult['expectedWord']}'.");

    // Note: La gestion d'erreur r√©elle de l'appel MCP devrait √™tre g√©r√©e par l'environnement
    // et potentiellement communiqu√©e retour √† l'application si n√©cessaire.
  }

  // --- Fonctions ajout√©es pour l'√©valuation finale ---

  Future<void> _completeExercise() async {
    if (!mounted) return;
    setState(() => _isProcessing = true); // Afficher l'indicateur pendant le feedback

    try {
      // 1. Calculer le score global moyen
      double averageScore = 0;
      if (_sessionResults.isNotEmpty) {
        averageScore = _sessionResults
                .map((r) => (r['globalScore'] as num?)?.toDouble() ?? 0.0)
                .reduce((a, b) => a + b) /
            _sessionResults.length;
      }

      // 2. Obtenir le feedback de l'IA
      _openAiFeedback = await _getOpenAiFeedback();

      // 3. Afficher les r√©sultats
      _showResults(averageScore.round(), _openAiFeedback);

    } catch (e) {
      ConsoleLogger.error("Erreur lors de la compl√©tion de l'exercice: $e");
      if (mounted) {
        ScaffoldMessenger.of(context).showSnackBar(
          SnackBar(content: Text('Erreur lors de la finalisation: ${e.toString()}')),
        );
        // Optionnel: Naviguer quand m√™me vers les r√©sultats avec un message d'erreur
        _showResults(0, "Erreur lors de la g√©n√©ration du feedback final.");
      }
    } finally {
      if (mounted) {
        setState(() => _isProcessing = false);
      }
    }
  }

  Future<String> _getOpenAiFeedback() async {
    ConsoleLogger.info("G√©n√©ration du feedback final OpenAI...");
    if (_sessionResults.isEmpty) {
      return "Aucun mot n'a √©t√© enregistr√© pour g√©n√©rer un feedback.";
    }

    try {
      // Agr√©ger les m√©triques pertinentes de tous les mots
      List<Map<String, dynamic>> wordMetricsList = [];
      for (var result in _sessionResults) {
        wordMetricsList.add({
          'mot': result['expectedWord'],
          'score_global': result['globalScore'],
          'syllabes_problematiques': result['problematicSyllables'],
          'transcription': result['transcription'],
          // Ajouter d'autres m√©triques si n√©cessaire, ex: scores sp√©cifiques
          'accuracy_score': (result['rawPronunciationResult'] as AzurePronunciationAssessmentResult?)?.nBest.firstOrNull?.pronunciationAssessment?.accuracyScore,
          'fluency_score': (result['rawPronunciationResult'] as AzurePronunciationAssessmentResult?)?.nBest.firstOrNull?.pronunciationAssessment?.fluencyScore,
        });
      }

      // Utiliser une structure simple pour le prompt global
      final aggregatedMetrics = {
        'nombre_mots': _sessionResults.length,
        'score_moyen': (_sessionResults.isNotEmpty) ? (_sessionResults.map((r) => (r['globalScore'] as num?)?.toDouble() ?? 0.0).reduce((a, b) => a + b) / _sessionResults.length).toStringAsFixed(1) : 'N/A',
        'details_par_mot': wordMetricsList, // Envoyer les d√©tails pour chaque mot
      };

      final feedback = await _openAIFeedbackService.generateFeedback(
        exerciseType: 'Pr√©cision Syllabique',
        exerciseLevel: _difficultyToString(widget.exercise.difficulty),
        spokenText: _sessionResults.map((r) => r['transcription'] ?? '').join(' '), // Concat√©ner les transcriptions
        expectedText: _wordList.join(' '), // Concat√©ner les mots attendus
        metrics: aggregatedMetrics,
      );
      return feedback;
    } catch (e) {
      ConsoleLogger.error('Erreur feedback OpenAI final: $e');
      return 'Erreur lors de la g√©n√©ration du feedback IA final.';
    }
  }

  void _showResults(int finalScore, String feedback) {
    if (!mounted) return;
    // Utiliser Future.delayed pour s'assurer que la navigation se fait apr√®s le cycle de build actuel
    Future.delayed(Duration.zero, () {
      if (!mounted) return; // V√©rifier √† nouveau au cas o√π le widget serait d√©mont√© pendant le d√©lai

      // Pr√©parer les donn√©es √† passer √† l'√©cran de r√©sultats
      final resultsData = {
        'score': finalScore,
        'commentaires': feedback,
        'details': {
          'session_results': _sessionResults
        }
      };

      // Utiliser GoRouter pour naviguer vers l'√©cran de r√©sultats.
      // 'go' est souvent plus robuste que 'pushReplacement' dans des contextes asynchrones.
      // Assurez-vous que AppRoutes.exerciseResult ('/exercise_result') est correctement d√©fini dans votre configuration GoRouter
      // et qu'il accepte un Map<String, dynamic> comme 'extra' contenant 'exercise' et 'results'.
      GoRouter.of(context).go(
        AppRoutes.exerciseResult, // Utiliser le CHEMIN de la route d√©fini dans AppRoutes
        extra: {
          'exercise': widget.exercise,
          'results': resultsData,
        },
      );
    });
  }

  // --- Fin des fonctions ajout√©es ---


  // Fonction pour repasser en mode SAFE (appel√©e dans dispose)
  Future<void> _setDatabaseSafeMode(bool safe) async {
    print("[Flutter] Indication pour r√©gler le mode DB sur ${safe ? 'SAFE' : 'UNSAFE'}...");
    // Indiquer √† l'environnement d'ex√©cuter l'outil MCP
    print("MCP_EXECUTE_TOOL: server=github.com/alexander-zuev/supabase-mcp-server tool=live_dangerously service=database enable_unsafe_mode=${!safe}");
    print("[Flutter] Indication envoy√©e (simulation).");
  }


  Future<Directory> getTemporaryDirectory() async {
    return await getApplicationDocumentsDirectory();
  }

  // Helper pour convertir la difficult√© en String pour OpenAI
  String _difficultyToString(ExerciseDifficulty difficulty) {
    switch (difficulty) {
      case ExerciseDifficulty.facile: return 'Facile';
      case ExerciseDifficulty.moyen: return 'Moyen';
      case ExerciseDifficulty.difficile: return 'Difficile';
      default: return 'Moyen'; // Fallback
    }
  }

  // M√©thode pour afficher la modale d'information
  void _showInfoModal() {
    showDialog(
      context: context,
      builder: (context) => InfoModal(
        title: widget.exercise.title,
        description: widget.exercise.objective ?? "Am√©liorer la clart√© syllabique.",
        benefits: const [
          "Discours plus clair et plus facile √† comprendre.",
          "R√©duction des mots 'mang√©s' ou indistincts.",
          "Meilleure articulation des mots longs ou complexes.",
          "Confiance accrue lors de la prise de parole.",
        ],
        instructions: "1. √âcoutez le mod√®le audio (syllabes puis mot entier).\n"
            "2. Appuyez sur le bouton micro et prononcez le mot affich√©.\n"
            "3. Concentrez-vous sur la prononciation distincte de CHAQUE syllabe.\n"
            "4. Rel√¢chez le bouton pour terminer l'enregistrement.\n"
            "5. R√©p√©tez pour les mots suivants.",
        backgroundColor: const Color(0xFFFF9500), // Correction couleur
      ),
    );
  }

  @override
  Widget build(BuildContext context) {
    // Utiliser la couleur de la cat√©gorie Clart√©/Expressivit√© (0xFFFF9500)
    const Color categoryColor = Color(0xFFFF9500);

    return Scaffold(
      backgroundColor: AppTheme.darkBackground,
      appBar: AppBar(
        backgroundColor: Colors.transparent,
        elevation: 0,
        systemOverlayStyle: SystemUiOverlayStyle.light,
        leading: IconButton(
          icon: const Icon(Icons.arrow_back),
          onPressed: () => Navigator.maybePop(context),
          color: Colors.white,
        ),
        title: Text(
          widget.exercise.title,
          style: const TextStyle(
              fontSize: 20, fontWeight: FontWeight.bold, color: Colors.white),
        ),
        actions: [
          IconButton(
            icon: Container(
              padding: const EdgeInsets.all(4),
              decoration: BoxDecoration(
                shape: BoxShape.circle,
                color: categoryColor.withOpacity(0.2),
              ),
              child: const Icon(
                Icons.info_outline,
                color: categoryColor,
              ),
            ),
            tooltip: '√Ä propos de cet exercice',
            onPressed: _showInfoModal, // Appel de la m√©thode d√©finie
          ),
        ],
      ),
      body: _isLoading
          ? const Center(child: CircularProgressIndicator())
          : _buildExerciseUI(categoryColor),
    );
  }

  // Widget principal de l'UI de l'exercice
  Widget _buildExerciseUI(Color categoryColor) {
    return Padding(
      padding: const EdgeInsets.symmetric(horizontal: 24.0),
      child: Column(
        children: [
          Expanded(
            child: SingleChildScrollView(
              child: Column(
                mainAxisAlignment: MainAxisAlignment.center,
                children: [
                  const SizedBox(height: 40),
                  Text(
                    _currentWord,
                    style: Theme.of(context).textTheme.displaySmall?.copyWith(color: Colors.white),
                    textAlign: TextAlign.center,
                  ),
                  const SizedBox(height: 15),
                  if (_currentSyllables.isNotEmpty)
                    Text(
                      _currentSyllables.join(' ‚Ä¢ '),
                      style: Theme.of(context).textTheme.headlineMedium?.copyWith(color: Colors.white70),
                      textAlign: TextAlign.center,
                      softWrap: true,
                    )
                  else if (!_isLoading)
                     Text(
                       "(D√©composition syllabique non disponible)",
                       style: Theme.of(context).textTheme.bodyMedium?.copyWith(color: Colors.grey),
                       textAlign: TextAlign.center,
                     ),
                  const SizedBox(height: 30),
                  const Text(
                    "Prononcez clairement chaque syllabe",
                    style: TextStyle(color: Colors.white70, fontSize: 16),
                    textAlign: TextAlign.center,
                  ),
                   const SizedBox(height: 40),
                   TextButton.icon(
                     onPressed: _isLoading || _isRecording || _isProcessing || _currentSyllables.isEmpty || _currentWord.isEmpty ? null : _playTtsDemo,
                     icon: Icon(Icons.volume_up, color: _isLoading || _isRecording || _isProcessing || _currentSyllables.isEmpty || _currentWord.isEmpty ? Colors.grey : Colors.white),
                     label: Text(
                       "√âcouter le mod√®le",
                       style: TextStyle(color: _isLoading || _isRecording || _isProcessing || _currentSyllables.isEmpty || _currentWord.isEmpty ? Colors.grey : Colors.white),
                     ),
                     style: TextButton.styleFrom(
                       padding: const EdgeInsets.symmetric(horizontal: 16, vertical: 8),
                     ),
                   ),
                   const SizedBox(height: 20),
                ],
              ),
            ),
          ),
          if (_isProcessing)
            const Padding(
              padding: EdgeInsets.symmetric(vertical: 16.0),
              child: Column(
                children: [
                  CircularProgressIndicator(),
                  SizedBox(height: 8),
                  Text("Analyse en cours...", style: TextStyle(color: Colors.white70)),
                ],
              ),
            ),
          Padding(
            padding: const EdgeInsets.only(bottom: 40.0, top: 10.0),
            child: PulsatingMicrophoneButton(
              size: 72,
              isRecording: _isRecording,
              onPressed: (_isLoading || _isProcessing || _currentWord.isEmpty)
                  ? () {}
                  : (_isRecording ? _stopRecording : _startRecording),
              baseColor: categoryColor,
              recordingColor: AppTheme.accentRed,
            ),
          ),
        ],
      ),
    );
  }
}
