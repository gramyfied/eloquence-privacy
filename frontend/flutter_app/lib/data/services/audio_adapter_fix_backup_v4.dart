import 'dart:async';
import 'dart:typed_data';
import 'dart:convert';
import 'dart:math' as math;
import 'package:flutter/foundation.dart';
import 'package:livekit_client/livekit_client.dart' hide ConnectionState;
import 'package:permission_handler/permission_handler.dart';
import '../../core/utils/logger_service.dart' as app_logger;
import '../../src/services/livekit_service.dart';
import '../models/session_model.dart';
import 'audio_stream_player_fixed_v2.dart';
import 'audio_format_detector_fixed.dart';

/// Correctif pour les probl√®mes d'audio dans l'application
/// 
/// Cette classe √©tend les fonctionnalit√©s de l'adaptateur audio LiveKit
/// pour r√©soudre les probl√®mes d'enregistrement et de lecture audio.
class AudioAdapterFix {
  static const String _tag = 'AudioAdapterFix';
  
  final LiveKitService _livekitService;
  AudioStreamPlayerFixedV2? _audioStreamPlayer;
  
  // Callbacks pour les √©v√©nements audio
  Function(String)? onTextReceived;
  Function(String)? onAudioUrlReceived;
  Function(Map<String, dynamic>)? onFeedbackReceived;
  Function(String)? onError;
  
  bool _isInitialized = false;
  bool _isRecording = false;
  bool _isConnected = false;
  
  // SOLUTION ANTI-BOUCLE NIVEAU 1 : Flag de contr√¥le de r√©ception audio
  bool _acceptingAudioData = false;
  
  // DIAGNOSTIC BOUCLE INFINIE - Variables de suivi
  DateTime? _lastAudioDataCallTime;
  int _audioDataCallCounter = 0;
  
  /// Cr√©e un nouveau correctif pour l'adaptateur audio
  AudioAdapterFix(this._livekitService) {
    app_logger.logger.i(_tag, 'üéµ [AUDIO_FIX] AudioAdapterFix constructor called.');
    _setupListeners();
    _initializeAudioPlayer();
  }
  
  /// Initialise le lecteur audio
  Future<void> _initializeAudioPlayer() async {
    app_logger.logger.i(_tag, 'üéµ [AUDIO_FIX] _initializeAudioPlayer called.');
    
    try {
      _audioStreamPlayer = AudioStreamPlayerFixedV2();
      await _audioStreamPlayer!.initialize();
      _isInitialized = true;
      app_logger.logger.i(_tag, 'üéµ [AUDIO_FIX] Lecteur audio V2 (48kHz) initialis√© avec succ√®s');
      
      // Test de fonctionnement d√©sactiv√© pour √©viter les boucles
      // await _audioStreamPlayer!.testPlayback();
    } catch (e) {
      app_logger.logger.e(_tag, 'Erreur lors de l\'initialisation du lecteur audio', e);
      onError?.call('Erreur lors de l\'initialisation du lecteur audio: $e');
    }
  }
  
  /// Configure les √©couteurs d'√©v√©nements LiveKit
  void _setupListeners() {
    // √âcouter les √©v√©nements de donn√©es re√ßues
    _livekitService.onDataReceived = (data) {
      try {
        // V√©rifier si les donn√©es sont du texte JSON ou des donn√©es audio binaires
        if (data.length > 0 && data[0] == 123) { // 123 est le code ASCII pour '{'
          // Donn√©es JSON
          final jsonData = jsonDecode(utf8.decode(data));
          app_logger.logger.i(_tag, 'Donn√©es JSON re√ßues: $jsonData');
          _handleJsonData(jsonData);
        } else {
          // Donn√©es audio binaires - TOUJOURS TRAITER (la distinction IA/Utilisateur est faite dans LiveKitService)
          app_logger.logger.i(_tag, 'Donn√©es audio binaires re√ßues: ${data.length} octets');
          _handleAudioData(data);
        }
      } catch (e) {
        app_logger.logger.e(_tag, 'Erreur lors du traitement des donn√©es re√ßues', e);
      }
    };
    
    // √âcouter les √©v√©nements de connexion/d√©connexion
    _livekitService.onConnectionStateChanged = (state) {
      app_logger.logger.i(_tag, 'üîÑ [DIAGNOSTIC_CALLBACK] ===== CHANGEMENT √âTAT CONNEXION =====');
      app_logger.logger.i(_tag, 'üîÑ [DIAGNOSTIC_CALLBACK] Nouvel √©tat: $state');
      app_logger.logger.i(_tag, 'üîÑ [DIAGNOSTIC_CALLBACK] √âtat pr√©c√©dent _isConnected: $_isConnected');
      
      switch (state) {
        case ConnectionState.connecting:
          _isConnected = false;
          app_logger.logger.i(_tag, 'üîÑ [DIAGNOSTIC_CALLBACK] CONNECTING - _isConnected = false');
          break;
        case ConnectionState.connected:
          _isConnected = true;
          app_logger.logger.i(_tag, 'üîÑ [DIAGNOSTIC_CALLBACK] CONNECTED - _isConnected = true');
          app_logger.logger.i(_tag, '‚úÖ [DIAGNOSTIC_CALLBACK] CONNEXION √âTABLIE AVEC SUCC√àS!');
          break;
        case ConnectionState.reconnecting:
          _isConnected = false;
          app_logger.logger.i(_tag, 'üîÑ [DIAGNOSTIC_CALLBACK] RECONNECTING - _isConnected = false');
          break;
        case ConnectionState.disconnected:
          _isConnected = false;
          app_logger.logger.i(_tag, 'üîÑ [DIAGNOSTIC_CALLBACK] DISCONNECTED - _isConnected = false');
          break;
      }
      
      app_logger.logger.i(_tag, 'üîÑ [DIAGNOSTIC_CALLBACK] √âtat final _isConnected: $_isConnected');
      app_logger.logger.i(_tag, 'üîÑ [DIAGNOSTIC_CALLBACK] √âtat LiveKitService.isConnected: ${_livekitService.isConnected}');
      app_logger.logger.i(_tag, 'üîÑ [DIAGNOSTIC_CALLBACK] ===== FIN CHANGEMENT √âTAT CONNEXION =====');
    };
  }
  
  /// Traite les donn√©es JSON re√ßues
  void _handleJsonData(Map<String, dynamic> jsonData) {
    if (jsonData.containsKey('type')) {
      final messageType = jsonData['type'];
      
      // Message de type "text"
      if (messageType == 'text' && jsonData.containsKey('content')) {
        final textContent = jsonData['content'];
        app_logger.logger.i(_tag, 'Texte re√ßu: $textContent');
        onTextReceived?.call(textContent);
      }
      
      // Message de type "audio"
      else if (messageType == 'audio' && jsonData.containsKey('url')) {
        final audioUrl = jsonData['url'];
        app_logger.logger.i(_tag, 'URL audio re√ßue: $audioUrl');
        onAudioUrlReceived?.call(audioUrl);
      }
      
      // Message de type "feedback"
      else if (messageType == 'feedback' && jsonData.containsKey('data')) {
        app_logger.logger.i(_tag, 'Feedback re√ßu');
        onFeedbackReceived?.call(jsonData['data']);
      }
      
      // Message de type "error"
      else if (messageType == 'error' && jsonData.containsKey('message')) {
        app_logger.logger.e(_tag, 'Erreur re√ßue du serveur: ${jsonData['message']}');
        onError?.call(jsonData['message']);
      }
    } else {
      // Format alternatif (champs directs)
      if (jsonData.containsKey('text')) {
        app_logger.logger.i(_tag, 'Texte re√ßu: ${jsonData['text']}');
        onTextReceived?.call(jsonData['text']);
      }

      if (jsonData.containsKey('audio_url')) {
        app_logger.logger.i(_tag, 'URL audio re√ßue: ${jsonData['audio_url']}');
        onAudioUrlReceived?.call(jsonData['audio_url']);
      }
    }
  }
  
  /// SOLUTION D√âFINITIVE : Traite les donn√©es audio avec protection intelligente anti-boucle ET am√©lioration qualit√©
  void _handleAudioData(Uint8List audioData) {
    app_logger.logger.i(_tag, 'üö® [DIAGNOSTIC_BOUCLE_ADAPTER] ===== DONN√âES AUDIO RE√áUES =====');
    app_logger.logger.i(_tag, 'üö® [DIAGNOSTIC_BOUCLE_ADAPTER] Taille: ${audioData.length} octets');
    app_logger.logger.i(_tag, 'üö® [DIAGNOSTIC_BOUCLE_ADAPTER] Timestamp: ${DateTime.now().toIso8601String()}');
    
    // üéØ IMPORTANT : Les donn√©es arrivent ici SEULEMENT si elles ont pass√© le filtre dans LiveKitService
    // - Les donn√©es de l'IA passent TOUJOURS (pour que vous puissiez entendre l'IA)
    // - Les donn√©es utilisateur sont filtr√©es selon _acceptingAudioData
    
    app_logger.logger.i(_tag, 'üéµ [AUDIO_FIX] Traitement des donn√©es audio: ${audioData.length} octets');
    app_logger.logger.i(_tag, 'üéµ [AUDIO_FIX] Ces donn√©es ont √©t√© pr√©-filtr√©es par LiveKitService');
    
    // Analyser les premi√®res donn√©es pour debug
    if (audioData.length > 10) {
      final firstBytes = audioData.take(10).toList();
      app_logger.logger.i(_tag, 'üéµ [AUDIO_FIX] Premiers bytes: $firstBytes');
    }
    
    // üîß NOUVELLE CORRECTION QUALIT√â AUDIO AVEC D√âTECTEUR DE FORMAT
    app_logger.logger.i(_tag, 'üîß [QUALITY_FIX] Validation de la qualit√© audio...');
    
    // Utiliser le d√©tecteur de format audio corrig√© (sans conversions inutiles)
    final processingResult = AudioFormatDetectorFixed.processAudioData(audioData);
    if (!processingResult.isValid) {
      app_logger.logger.w(_tag, 'üîß [QUALITY_FIX] Donn√©es audio rejet√©es: ${processingResult.error}');
      app_logger.logger.i(_tag, 'üö® [DIAGNOSTIC_BOUCLE_ADAPTER] ===== FIN TRAITEMENT DONN√âES AUDIO (REJET√âES) =====');
      return;
    }
    
    final audioDataToPlay = processingResult.data!;
    app_logger.logger.i(_tag, 'üîß [QUALITY_FIX] Format d√©tect√©: ${processingResult.format}');
    app_logger.logger.i(_tag, 'üîß [QUALITY_FIX] Qualit√© audio: ${processingResult.quality?.toStringAsFixed(3)}');
    app_logger.logger.i(_tag, 'üîß [QUALITY_FIX] Donn√©es audio valid√©es - Taille: ${audioDataToPlay.length} octets');
    
    app_logger.logger.i(_tag, 'üö® [DIAGNOSTIC_BOUCLE_ADAPTER] √âtat lecteur:');
    app_logger.logger.i(_tag, 'üö® [DIAGNOSTIC_BOUCLE_ADAPTER]   - _audioStreamPlayer != null: ${_audioStreamPlayer != null}');
    app_logger.logger.i(_tag, 'üö® [DIAGNOSTIC_BOUCLE_ADAPTER]   - _isInitialized: $_isInitialized');
    
    if (_audioStreamPlayer != null && _isInitialized) {
      app_logger.logger.i(_tag, 'üéµ [AUDIO_FIX] Envoi des donn√©es audio au lecteur V2');
      app_logger.logger.i(_tag, 'üö® [DIAGNOSTIC_BOUCLE_ADAPTER] APPEL playChunk() - D√âBUT');
      
      // Utiliser les donn√©es audio sans modification
      _audioStreamPlayer!.playChunk(audioDataToPlay);
      
      app_logger.logger.i(_tag, 'üö® [DIAGNOSTIC_BOUCLE_ADAPTER] APPEL playChunk() - FIN');
      app_logger.logger.i(_tag, 'üîÑ [QUEUE_STATS] Stats queue: ${_audioStreamPlayer!.getQueueStats()}');
    } else {
      app_logger.logger.w(_tag, 'üéµ [AUDIO_FIX] Lecteur audio non initialis√©, initialisation en cours...');
      app_logger.logger.w(_tag, 'üö® [DIAGNOSTIC_BOUCLE_ADAPTER] INITIALISATION ASYNCHRONE D√âCLENCH√âE');
      _initializeAudioPlayer().then((_) {
        if (_audioStreamPlayer != null && _isInitialized) {
          app_logger.logger.i(_tag, 'üéµ [AUDIO_FIX] Lecteur audio initialis√©, lecture des donn√©es audio');
          app_logger.logger.i(_tag, 'üö® [DIAGNOSTIC_BOUCLE_ADAPTER] APPEL playChunk() DIFF√âR√â - D√âBUT');
          _audioStreamPlayer!.playChunk(audioDataToPlay);
          app_logger.logger.i(_tag, 'üö® [DIAGNOSTIC_BOUCLE_ADAPTER] APPEL playChunk() DIFF√âR√â - FIN');
        }
      });
    }
    
    app_logger.logger.i(_tag, 'üö® [DIAGNOSTIC_BOUCLE_ADAPTER] ===== FIN TRAITEMENT DONN√âES AUDIO =====');
  }
  
  /// V√©rifie et demande les permissions du microphone
  Future<bool> checkMicrophonePermission() async {
    app_logger.logger.i(_tag, 'V√©rification des permissions du microphone...');
    
    // V√©rifier si la permission est d√©j√† accord√©e
    var status = await Permission.microphone.status;
    app_logger.logger.i(_tag, 'Statut actuel de la permission microphone: $status');
    
    if (status.isGranted) {
      app_logger.logger.i(_tag, 'Permission microphone d√©j√† accord√©e');
      return true;
    }
    
    // Demander la permission
    app_logger.logger.i(_tag, 'Demande de permission microphone...');
    status = await Permission.microphone.request();
    app_logger.logger.i(_tag, 'R√©sultat de la demande de permission: $status');
    
    return status.isGranted;
  }
  
  /// V√©rifie l'√©tat du microphone
  Future<bool> checkMicrophoneState() async {
    app_logger.logger.i(_tag, 'V√©rification de l\'√©tat du microphone...');
    
    try {
      // Cr√©er une piste audio locale temporaire pour tester le microphone
      final track = await LocalAudioTrack.create(
        const AudioCaptureOptions(
          echoCancellation: true,
          noiseSuppression: true,
          autoGainControl: true,
        ),
      );
      
      // Si la piste a √©t√© cr√©√©e avec succ√®s, le microphone fonctionne
      if (track != null) {
        app_logger.logger.i(_tag, 'Microphone fonctionnel');
        
        // Lib√©rer la piste temporaire
        await track.stop();
        
        return true;
      } else {
        app_logger.logger.e(_tag, 'Impossible de cr√©er une piste audio locale');
        return false;
      }
    } catch (e) {
      app_logger.logger.e(_tag, 'Erreur lors de la v√©rification du microphone', e);
      return false;
    }
  }
  
  /// D√©marre l'enregistrement audio
  Future<bool> startRecording() async {
    app_logger.logger.i(_tag, 'üé§ [DIAGNOSTIC_RECORDING] ===== D√âBUT D√âMARRAGE ENREGISTREMENT =====');
    app_logger.logger.i(_tag, 'üé§ [DIAGNOSTIC_RECORDING] √âtat initial - _isRecording: $_isRecording');
    app_logger.logger.i(_tag, 'üé§ [DIAGNOSTIC_RECORDING] √âtat initial - _isConnected: $_isConnected');
    app_logger.logger.i(_tag, 'üé§ [DIAGNOSTIC_RECORDING] √âtat initial - _isInitialized: $_isInitialized');
    
    if (_isRecording) {
      app_logger.logger.w(_tag, '‚ö†Ô∏è [DIAGNOSTIC_RECORDING] L\'enregistrement est d√©j√† en cours');
      return true;
    }
    
    // CORRECTION : V√©rifier l'√©tat de connexion r√©el du service LiveKit
    final isReallyConnected = _livekitService.isConnected;
    final isConnecting = _livekitService.isConnecting;
    final localParticipant = _livekitService.localParticipant;
    final room = _livekitService.room;
    
    app_logger.logger.i(_tag, 'üé§ [DIAGNOSTIC_RECORDING] √âtat de connexion LiveKit:');
    app_logger.logger.i(_tag, 'üé§ [DIAGNOSTIC_RECORDING]   - _isConnected (local): $_isConnected');
    app_logger.logger.i(_tag, 'üé§ [DIAGNOSTIC_RECORDING]   - isReallyConnected (service): $isReallyConnected');
    app_logger.logger.i(_tag, 'üé§ [DIAGNOSTIC_RECORDING]   - isConnecting (service): $isConnecting');
    app_logger.logger.i(_tag, 'üé§ [DIAGNOSTIC_RECORDING]   - localParticipant != null: ${localParticipant != null}');
    app_logger.logger.i(_tag, 'üé§ [DIAGNOSTIC_RECORDING]   - room != null: ${room != null}');
    
    if (room != null) {
      app_logger.logger.i(_tag, 'üé§ [DIAGNOSTIC_RECORDING]   - room.name: ${room.name}');
      app_logger.logger.i(_tag, 'üé§ [DIAGNOSTIC_RECORDING]   - room.connectionState: ${room.connectionState}');
    }
    
    if (localParticipant != null) {
      app_logger.logger.i(_tag, 'üé§ [DIAGNOSTIC_RECORDING]   - localParticipant.identity: ${localParticipant.identity}');
      app_logger.logger.i(_tag, 'üé§ [DIAGNOSTIC_RECORDING]   - localParticipant.audioTrackPublications.length: ${localParticipant.audioTrackPublications.length}');
    }
    
    if (!isReallyConnected) {
      app_logger.logger.e(_tag, '‚ùå [DIAGNOSTIC_RECORDING] Non connect√© √† LiveKit, impossible de d√©marrer l\'enregistrement');
      app_logger.logger.e(_tag, '‚ùå [DIAGNOSTIC_RECORDING] Raison: isReallyConnected = false');
      onError?.call('Impossible de d√©marrer l\'enregistrement: non connect√© √† LiveKit');
      return false;
    }
    
    app_logger.logger.i(_tag, '‚úÖ [DIAGNOSTIC_RECORDING] Connexion LiveKit confirm√©e, d√©marrage de l\'enregistrement...');
    
    // V√©rifier les permissions du microphone
    app_logger.logger.i(_tag, 'üé§ [DIAGNOSTIC_RECORDING] V√©rification des permissions du microphone...');
    final hasPermission = await checkMicrophonePermission();
    app_logger.logger.i(_tag, 'üé§ [DIAGNOSTIC_RECORDING] Permission microphone: $hasPermission');
    
    if (!hasPermission) {
      app_logger.logger.e(_tag, '‚ùå [DIAGNOSTIC_RECORDING] Permission microphone non accord√©e');
      onError?.call('Impossible de d√©marrer l\'enregistrement: permission microphone non accord√©e');
      return false;
    }
    
    // V√©rifier l'√©tat du microphone
    app_logger.logger.i(_tag, 'üé§ [DIAGNOSTIC_RECORDING] V√©rification de l\'√©tat du microphone...');
    final microphoneWorking = await checkMicrophoneState();
    app_logger.logger.i(_tag, 'üé§ [DIAGNOSTIC_RECORDING] Microphone fonctionnel: $microphoneWorking');
    
    if (!microphoneWorking) {
      app_logger.logger.e(_tag, '‚ùå [DIAGNOSTIC_RECORDING] Microphone non fonctionnel');
      onError?.call('Impossible de d√©marrer l\'enregistrement: microphone non fonctionnel');
      return false;
    }
    
    try {
      // üõ°Ô∏è PROTECTION ANTI-BOUCLE NIVEAU 1 : Activer la r√©ception des donn√©es audio
      app_logger.logger.i(_tag, 'üõ°Ô∏è [ANTI_BOUCLE_NIVEAU_1] Activation de la r√©ception audio dans LiveKitService...');
      _livekitService.startAcceptingAudioData();
      
      // NIVEAU 1 : ACTIVER LA R√âCEPTION AUDIO AVANT LA PUBLICATION
      _acceptingAudioData = true;
      app_logger.logger.i(_tag, 'üé§ [DIAGNOSTIC_RECORDING] _acceptingAudioData = true - R√©ception audio activ√©e');
      
      // Publier l'audio local
      app_logger.logger.i(_tag, 'üé§ [DIAGNOSTIC_RECORDING] Publication de l\'audio local...');
      app_logger.logger.i(_tag, 'üé§ [DIAGNOSTIC_RECORDING] Appel de _livekitService.publishMyAudio()...');
      
      await _livekitService.publishMyAudio();
      
      app_logger.logger.i(_tag, 'üé§ [DIAGNOSTIC_RECORDING] publishMyAudio() termin√© avec succ√®s');
      
      // V√©rifier l'√©tat apr√®s publication
      if (localParticipant != null) {
        app_logger.logger.i(_tag, 'üé§ [DIAGNOSTIC_RECORDING] √âtat apr√®s publication:');
        app_logger.logger.i(_tag, 'üé§ [DIAGNOSTIC_RECORDING]   - audioTrackPublications.length: ${localParticipant.audioTrackPublications.length}');
        for (final pub in localParticipant.audioTrackPublications) {
          app_logger.logger.i(_tag, 'üé§ [DIAGNOSTIC_RECORDING]   - publication: ${pub.sid}, muted: ${pub.muted}, subscribed: ${pub.subscribed}');
        }
      }
      
      // Informer le serveur que l'enregistrement a commenc√©
      app_logger.logger.i(_tag, 'üé§ [DIAGNOSTIC_RECORDING] Envoi du message de contr√¥le recording_started...');
      _sendControlMessage('recording_started');
      
      _isRecording = true;
      app_logger.logger.i(_tag, '‚úÖ [DIAGNOSTIC_RECORDING] Enregistrement d√©marr√© avec succ√®s');
      app_logger.logger.i(_tag, '‚úÖ [DIAGNOSTIC_RECORDING] _isRecording = $_isRecording');
      app_logger.logger.i(_tag, 'üé§ [DIAGNOSTIC_RECORDING] ===== FIN D√âMARRAGE ENREGISTREMENT (SUCC√àS) =====');
      return true;
    } catch (e, stackTrace) {
      app_logger.logger.e(_tag, '‚ùå [DIAGNOSTIC_RECORDING] Exception lors du d√©marrage de l\'enregistrement: $e');
      app_logger.logger.e(_tag, '‚ùå [DIAGNOSTIC_RECORDING] StackTrace: $stackTrace');
      onError?.call('Erreur lors du d√©marrage de l\'enregistrement: $e');
      app_logger.logger.i(_tag, 'üé§ [DIAGNOSTIC_RECORDING] ===== FIN D√âMARRAGE ENREGISTREMENT (√âCHEC) =====');
      return false;
    }
  }
  
  /// Arr√™te l'enregistrement audio
  Future<bool> stopRecording() async {
    app_logger.logger.i(_tag, 'Arr√™t de l\'enregistrement audio...');
    
    if (!_isRecording) {
      app_logger.logger.w(_tag, 'L\'enregistrement n\'est pas en cours');
      return true;
    }
    
    try {
      // üõ°Ô∏è PROTECTION ANTI-BOUCLE NIVEAU 1 : D√©sactiver la r√©ception des donn√©es audio
      app_logger.logger.i(_tag, 'üõ°Ô∏è [ANTI_BOUCLE_NIVEAU_1] D√©sactivation de la r√©ception audio dans LiveKitService...');
      _livekitService.stopAcceptingAudioData();
      
      // NIVEAU 1 : D√âSACTIVER LA R√âCEPTION AUDIO IMM√âDIATEMENT
      _acceptingAudioData = false;
      app_logger.logger.i(_tag, 'üõë [ANTI_BOUCLE] _acceptingAudioData = false - R√©ception audio d√©sactiv√©e');
      
      // Arr√™ter la publication audio
      app_logger.logger.i(_tag, 'Arr√™t de la publication audio...');
      await _livekitService.unpublishMyAudio();
      
      // Informer le serveur que l'enregistrement est termin√©
      _sendControlMessage('recording_stopped');
      
      _isRecording = false;
      app_logger.logger.i(_tag, 'Enregistrement arr√™t√© avec succ√®s');
      return true;
    } catch (e) {
      app_logger.logger.e(_tag, 'Erreur lors de l\'arr√™t de l\'enregistrement', e);
      onError?.call('Erreur lors de l\'arr√™t de l\'enregistrement: $e');
      
      // M√™me en cas d'erreur, on consid√®re que l'enregistrement est arr√™t√©
      _isRecording = false;
      return false;
    }
  }
  
  /// Connecte √† LiveKit avec les informations de session
  Future<bool> connectToLiveKit(SessionModel session) async {
    app_logger.logger.i(_tag, 'üîß [DIAGNOSTIC_AUDIOFIX] ===== D√âBUT CONNEXION AUDIOFIX =====');
    app_logger.logger.i(_tag, 'üîß [DIAGNOSTIC_AUDIOFIX] Session ID: ${session.sessionId}');
    app_logger.logger.i(_tag, 'üîß [DIAGNOSTIC_AUDIOFIX] Room Name: ${session.roomName}');
    app_logger.logger.i(_tag, 'üîß [DIAGNOSTIC_AUDIOFIX] LiveKit URL: ${session.livekitUrl}');
    app_logger.logger.i(_tag, 'üîß [DIAGNOSTIC_AUDIOFIX] Token pr√©sent: ${session.token.isNotEmpty}');
    app_logger.logger.i(_tag, 'üîß [DIAGNOSTIC_AUDIOFIX] Token longueur: ${session.token.length}');
    app_logger.logger.i(_tag, 'üîß [DIAGNOSTIC_AUDIOFIX] √âtat initial AudioFix - _isConnected: $_isConnected');
    app_logger.logger.i(_tag, 'üîß [DIAGNOSTIC_AUDIOFIX] √âtat initial AudioFix - _isInitialized: $_isInitialized');
    app_logger.logger.i(_tag, 'üîß [DIAGNOSTIC_AUDIOFIX] √âtat initial AudioFix - _isRecording: $_isRecording');
    app_logger.logger.i(_tag, 'üîß [DIAGNOSTIC_AUDIOFIX] √âtat initial LiveKitService - isConnected: ${_livekitService.isConnected}');
    app_logger.logger.i(_tag, 'üîß [DIAGNOSTIC_AUDIOFIX] √âtat initial LiveKitService - isConnecting: ${_livekitService.isConnecting}');
    
    try {
      // Extraire les informations de la session
      final livekitUrl = session.livekitUrl;
      final token = session.token;
      final roomName = session.roomName;
      
      app_logger.logger.i(_tag, 'üîß [DIAGNOSTIC_AUDIOFIX] Validation des param√®tres...');
      if (livekitUrl.isEmpty) {
        app_logger.logger.e(_tag, '‚ùå [DIAGNOSTIC_AUDIOFIX] URL LiveKit vide!');
        return false;
      }
      if (token.isEmpty) {
        app_logger.logger.e(_tag, '‚ùå [DIAGNOSTIC_AUDIOFIX] Token LiveKit vide!');
        return false;
      }
      if (roomName.isEmpty) {
        app_logger.logger.e(_tag, '‚ùå [DIAGNOSTIC_AUDIOFIX] Room name vide!');
        return false;
      }
      
      app_logger.logger.i(_tag, 'üîß [DIAGNOSTIC_AUDIOFIX] Param√®tres valid√©s, appel de _livekitService.connectWithToken()...');
      
      // D√©clencher la connexion r√©elle via le service LiveKit
      final success = await _livekitService.connectWithToken(
        livekitUrl,
        token,
        roomName: roomName,
      );
      
      app_logger.logger.i(_tag, 'üîß [DIAGNOSTIC_AUDIOFIX] R√©sultat connectWithToken: $success');
      app_logger.logger.i(_tag, 'üîß [DIAGNOSTIC_AUDIOFIX] √âtat apr√®s connexion LiveKitService - isConnected: ${_livekitService.isConnected}');
      app_logger.logger.i(_tag, 'üîß [DIAGNOSTIC_AUDIOFIX] √âtat apr√®s connexion LiveKitService - isConnecting: ${_livekitService.isConnecting}');
      app_logger.logger.i(_tag, 'üîß [DIAGNOSTIC_AUDIOFIX] √âtat apr√®s connexion AudioFix - _isConnected: $_isConnected');
      
      if (success) {
        app_logger.logger.i(_tag, '‚úÖ [DIAGNOSTIC_AUDIOFIX] Connexion LiveKit r√©ussie');
        app_logger.logger.i(_tag, '‚úÖ [DIAGNOSTIC_AUDIOFIX] L\'√©tat _isConnected sera mis √† jour via le callback onConnectionStateChanged');
        
        // Attendre un court d√©lai pour que les callbacks se d√©clenchent
        await Future.delayed(const Duration(milliseconds: 500));
        
        app_logger.logger.i(_tag, '‚úÖ [DIAGNOSTIC_AUDIOFIX] √âtat final apr√®s d√©lai - _isConnected: $_isConnected');
        app_logger.logger.i(_tag, '‚úÖ [DIAGNOSTIC_AUDIOFIX] √âtat final apr√®s d√©lai - LiveKitService.isConnected: ${_livekitService.isConnected}');
        
        return true;
      } else {
        app_logger.logger.e(_tag, '‚ùå [DIAGNOSTIC_AUDIOFIX] √âchec de la connexion LiveKit');
        return false;
      }
    } catch (e, stackTrace) {
      app_logger.logger.e(_tag, '‚ùå [DIAGNOSTIC_AUDIOFIX] Exception lors de la connexion LiveKit: $e');
      app_logger.logger.e(_tag, '‚ùå [DIAGNOSTIC_AUDIOFIX] StackTrace: $stackTrace');
      onError?.call('Erreur de connexion LiveKit: $e');
      return false;
    } finally {
      app_logger.logger.i(_tag, 'üîß [DIAGNOSTIC_AUDIOFIX] ===== FIN CONNEXION AUDIOFIX =====');
    }
  }

  /// Envoie un message de contr√¥le au serveur
  void _sendControlMessage(String type, [Map<String, dynamic>? data]) {
    try {
      final message = {
        'type': type,
        'timestamp': DateTime.now().toIso8601String(),
        if (data != null) ...data,
      };
      
      final jsonMessage = jsonEncode(message);
      _livekitService.sendData(utf8.encode(jsonMessage));
      app_logger.logger.i(_tag, 'Message de contr√¥le envoy√©: $type');
    } catch (e) {
      app_logger.logger.e(_tag, 'Erreur lors de l\'envoi du message de contr√¥le', e);
    }
  }
  
  /// Lib√®re les ressources
  Future<void> dispose() async {
    app_logger.logger.i(_tag, 'Lib√©ration des ressources...');
    
    // üõ°Ô∏è PROTECTION ANTI-BOUCLE NIVEAU 1 : D√©sactiver la r√©ception des donn√©es audio
    app_logger.logger.i(_tag, 'üõ°Ô∏è [ANTI_BOUCLE_NIVEAU_1] D√©sactivation de la r√©ception audio dans LiveKitService lors du dispose...');
    _livekitService.stopAcceptingAudioData();
    
    // NIVEAU 1 : D√âSACTIVER LA R√âCEPTION AUDIO IMM√âDIATEMENT
    _acceptingAudioData = false;
    app_logger.logger.i(_tag, 'üõë [ANTI_BOUCLE] _acceptingAudioData = false - R√©ception audio d√©sactiv√©e lors du dispose');
    
    // Arr√™ter l'enregistrement s'il est en cours
    if (_isRecording) {
      await stopRecording();
    }
    
    // Lib√©rer le lecteur audio
    if (_audioStreamPlayer != null) {
      await _audioStreamPlayer!.dispose();
      _audioStreamPlayer = null;
    }
    
    _isInitialized = false;
    app_logger.logger.i(_tag, 'Ressources lib√©r√©es');
  }
  
  /// V√©rifie si l'enregistrement est en cours
  bool get isRecording => _isRecording;
  
  /// V√©rifie si la connexion est √©tablie (utilise l'√©tat r√©el du service LiveKit)
  bool get isConnected => _livekitService.isConnected;
  
  /// V√©rifie si le lecteur audio est initialis√©
  bool get isInitialized => _isInitialized;
  
  /// V√©rifie si l'adaptateur accepte les donn√©es audio (protection anti-boucle)
  bool get isAcceptingAudioData => _acceptingAudioData;
  
  /// Acc√®s au lecteur audio pour les tests et diagnostics
  AudioStreamPlayerFixedV2? get audioStreamPlayer => _audioStreamPlayer;
  
  /// M√©thode publique pour les tests - traite les donn√©es audio
  void handleAudioDataForTesting(Uint8List audioData) {
    _handleAudioData(audioData);
  }
  
  /// Obtient les statistiques de la queue audio
  Map<String, dynamic> getAudioQueueStats() {
    if (_audioStreamPlayer != null) {
      return _audioStreamPlayer!.getQueueStats();
    }
    return {
      'error': 'AudioStreamPlayer not initialized',
      'isInitialized': _isInitialized,
    };
  }
  
  /// Valide et nettoie les donn√©es audio re√ßues
  Uint8List? _validateAndCleanAudioData(Uint8List rawData) {
    if (rawData.isEmpty) {
      app_logger.logger.w(_tag, 'üîß [QUALITY_FIX] ‚ùå Donn√©es audio vides');
      return null;
    }
    
    // V√©rifier si les donn√©es sont enti√®rement du silence (tous les bytes √† 0)
    bool isAllSilence = true;
    for (int i = 0; i < rawData.length; i++) {
      if (rawData[i] != 0) {
        isAllSilence = false;
        break;
      }
    }
    
    if (isAllSilence) {
      app_logger.logger.w(_tag, 'üîß [QUALITY_FIX] ‚ö†Ô∏è Donn√©es audio d√©tect√©es comme silence complet - ignor√©es');
      return null;
    }
    
    // V√©rifier la taille minimale pour un chunk audio valide
    if (rawData.length < 1024) {
      app_logger.logger.w(_tag, 'üîß [QUALITY_FIX] ‚ö†Ô∏è Chunk audio trop petit (${rawData.length} bytes) - ignor√©');
      return null;
    }
    
    // Analyser le niveau audio pour d√©tecter les donn√©es corrompues
    double averageLevel = _calculateAverageAudioLevel(rawData);
    if (averageLevel < 0.001) {
      app_logger.logger.w(_tag, 'üîß [QUALITY_FIX] ‚ö†Ô∏è Niveau audio trop faible ($averageLevel) - possiblement corrompu');
      return null;
    }
    
    app_logger.logger.i(_tag, 'üîß [QUALITY_FIX] ‚úÖ Donn√©es audio valides - Taille: ${rawData.length}, Niveau: ${averageLevel.toStringAsFixed(3)}');
    return rawData;
  }
  
  /// Calcule le niveau audio moyen pour d√©tecter les donn√©es corrompues
  double _calculateAverageAudioLevel(Uint8List audioData) {
    if (audioData.length < 2) return 0.0;
    
    double sum = 0.0;
    int sampleCount = 0;
    
    // Traiter les donn√©es comme des √©chantillons 16-bit (2 bytes par √©chantillon)
    for (int i = 0; i < audioData.length - 1; i += 2) {
      // Convertir 2 bytes en √©chantillon 16-bit sign√©
      int sample = (audioData[i + 1] << 8) | audioData[i];
      if (sample > 32767) sample -= 65536; // Conversion en sign√©
      
      // Calculer la valeur absolue pour le niveau
      sum += sample.abs() / 32768.0; // Normaliser entre 0 et 1
      sampleCount++;
    }
    
    return sampleCount > 0 ? sum / sampleCount : 0.0;
  }
  
  /// Applique un filtre de nettoyage audio basique
  Uint8List _applyAudioCleaning(Uint8List audioData) {
    if (audioData.length < 4) return audioData;
    
    // Cr√©er une copie pour le nettoyage
    Uint8List cleanedData = Uint8List.fromList(audioData);
    
    // Appliquer un filtre passe-bas simple pour r√©duire le bruit
    for (int i = 2; i < cleanedData.length - 2; i += 2) {
      // Moyenner avec les √©chantillons adjacents
      int current = (cleanedData[i + 1] << 8) | cleanedData[i];
      int prev = (cleanedData[i - 1] << 8) | cleanedData[i - 2];
      int next = (cleanedData[i + 3] << 8) | cleanedData[i + 2];
      
      // Conversion en sign√©
      if (current > 32767) current -= 65536;
      if (prev > 32767) prev -= 65536;
      if (next > 32767) next -= 65536;
      
      // Filtre simple (moyenne pond√©r√©e)
      int filtered = ((prev + current * 2 + next) / 4).round();
      
      // Reconversion en non-sign√©
      if (filtered < 0) filtered += 65536;
      
      // R√©√©crire les bytes
      cleanedData[i] = filtered & 0xFF;
      cleanedData[i + 1] = (filtered >> 8) & 0xFF;
    }
    
    app_logger.logger.i(_tag, 'üîß [QUALITY_FIX] üßπ Nettoyage audio appliqu√©');
    return cleanedData;
  }
  
  /// Normalise le volume audio
  Uint8List _normalizeVolume(Uint8List audioData, {double targetLevel = 0.7}) {
    if (audioData.length < 2) return audioData;
    
    // Trouver le niveau maximum
    double maxLevel = 0.0;
    for (int i = 0; i < audioData.length - 1; i += 2) {
      int sample = (audioData[i + 1] << 8) | audioData[i];
      if (sample > 32767) sample -= 65536;
      double level = sample.abs() / 32768.0;
      if (level > maxLevel) maxLevel = level;
    }
    
    if (maxLevel < 0.001) return audioData; // √âviter la division par z√©ro
    
    // Calculer le facteur de normalisation
    double normalizationFactor = targetLevel / maxLevel;
    
    // Limiter le facteur pour √©viter la distorsion
    if (normalizationFactor > 3.0) normalizationFactor = 3.0;
    
    // Appliquer la normalisation
    Uint8List normalizedData = Uint8List.fromList(audioData);
    for (int i = 0; i < normalizedData.length - 1; i += 2) {
      int sample = (normalizedData[i + 1] << 8) | normalizedData[i];
      if (sample > 32767) sample -= 65536;
      
      // Appliquer la normalisation
      int normalizedSample = (sample * normalizationFactor).round();
      
      // Limiter pour √©viter le clipping
      normalizedSample = math.max(-32768, math.min(32767, normalizedSample));
      
      // Reconversion
      if (normalizedSample < 0) normalizedSample += 65536;
      
      normalizedData[i] = normalizedSample & 0xFF;
      normalizedData[i + 1] = (normalizedSample >> 8) & 0xFF;
    }
    
    app_logger.logger.i(_tag, 'üîß [QUALITY_FIX] üîä Volume normalis√© (facteur: ${normalizationFactor.toStringAsFixed(2)})');
    return normalizedData;
  }
}