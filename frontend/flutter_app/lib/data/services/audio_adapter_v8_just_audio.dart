import 'dart:async';
import 'dart:convert';
import 'dart:typed_data';
import 'package:flutter/foundation.dart';
import 'package:just_audio/just_audio.dart';
import '../../src/services/livekit_service.dart';
import '../models/session_model.dart';
import 'audio_format_detector_v2.dart';

/// Adaptateur audio V8 utilisant just_audio avec StreamAudioSource
/// Solution d√©finitive qui √©limine les MissingPluginException
class AudioAdapterV8JustAudio {
  static const String _logTag = 'AudioAdapterV8JustAudio';
  
  // Services
  final LiveKitService _liveKitService;
  late final AudioPlayer _audioPlayer;
  
  // √âtat de l'adaptateur
  bool _isInitialized = false;
  bool _isRecording = false;
  bool _isConnected = false;
  
  // Statistiques
  int _chunksReceived = 0;
  int _chunksProcessed = 0;
  int _chunksRejected = 0;
  DateTime? _lastDataTime;
  
  // Callbacks
  Function(String)? onTextReceived;
  Function(String)? onError;
  Function()? onRecordingStarted;
  Function()? onRecordingStopped;
  
  AudioAdapterV8JustAudio(this._liveKitService) {
    _setupListeners();
  }
  
  /// Configure les √©couteurs d'√©v√©nements LiveKit
  void _setupListeners() {
    // √âcouter les √©v√©nements de donn√©es re√ßues
    _liveKitService.onDataReceived = (data) {
      try {
        // V√©rifier si les donn√©es sont du texte JSON ou des donn√©es audio binaires
        if (data.isNotEmpty && data[0] == 123) { // 123 est le code ASCII pour '{'
          // Donn√©es JSON
          final jsonData = jsonDecode(utf8.decode(data));
          debugPrint('üì® [$_logTag] Donn√©es JSON re√ßues via LiveKit: $jsonData');
          handleJsonData(jsonData);
        } else {
          // Donn√©es audio binaires
          debugPrint('üì• [$_logTag] Donn√©es audio binaires re√ßues via LiveKit: ${data.length} octets');
          handleAudioData(data);
        }
      } catch (e) {
        debugPrint('‚ùå [$_logTag] Erreur lors du traitement des donn√©es re√ßues: $e');
        onError?.call('Erreur traitement donn√©es: $e');
      }
    };
    
    // √âcouter les √©v√©nements de connexion/d√©connexion
    _liveKitService.onConnectionStateChanged = (state) {
      debugPrint('üîÑ [$_logTag] Changement d\'√©tat de connexion: $state');
      
      switch (state) {
        case ConnectionState.connecting:
          _isConnected = false;
          break;
        case ConnectionState.connected:
          _isConnected = true;
          debugPrint('‚úÖ [$_logTag] Connexion LiveKit √©tablie avec succ√®s!');
          break;
        case ConnectionState.reconnecting:
          _isConnected = false;
          break;
        case ConnectionState.disconnected:
          _isConnected = false;
          break;
      }
    };
  }
  
  /// Initialise l'adaptateur audio V8
  Future<bool> initialize() async {
    try {
      debugPrint('üéµ [$_logTag] ===== INITIALISATION ADAPTATEUR V8 =====');
      
      // Cr√©er l'instance AudioPlayer de just_audio
      _audioPlayer = AudioPlayer();
      
      debugPrint('‚úÖ [$_logTag] AudioPlayer just_audio cr√©√© avec succ√®s');
      
      _isInitialized = true;
      _isConnected = _liveKitService.isConnected;
      
      debugPrint('‚úÖ [$_logTag] Adaptateur V8 initialis√© avec succ√®s');
      debugPrint('üéµ [$_logTag] ===== FIN INITIALISATION ADAPTATEUR V8 =====');
      
      return true;
      
    } catch (e) {
      debugPrint('‚ùå [$_logTag] Erreur initialisation: $e');
      onError?.call('Erreur initialisation adaptateur V8: $e');
      return false;
    }
  }
  
  /// D√©marre l'enregistrement audio
  Future<bool> startRecording() async {
    try {
      debugPrint('üé§ [$_logTag] ===== D√âBUT D√âMARRAGE ENREGISTREMENT V8 =====');
      
      if (!_isInitialized) {
        debugPrint('‚ùå [$_logTag] Adaptateur non initialis√©');
        return false;
      }
      
      if (_isRecording) {
        debugPrint('‚ö†Ô∏è [$_logTag] Enregistrement d√©j√† en cours');
        return true;
      }
      
      debugPrint('üé§ [$_logTag] D√©marrage de l\'enregistrement...');
      
      // Activer la r√©ception audio dans LiveKit
      _liveKitService.startAcceptingAudioData();
      
      // Publier le microphone
      try {
        await _liveKitService.publishMyAudio();
        debugPrint('‚úÖ [$_logTag] Publication audio r√©ussie');
      } catch (e) {
        debugPrint('‚ùå [$_logTag] √âchec publication audio: $e');
        return false;
      }
      
      // Envoyer le message de d√©marrage
      await _sendControlMessage('recording_started');
      
      _isRecording = true;
      onRecordingStarted?.call();
      
      debugPrint('‚úÖ [$_logTag] Enregistrement d√©marr√© avec succ√®s');
      debugPrint('üé§ [$_logTag] ===== FIN D√âMARRAGE ENREGISTREMENT V8 =====');
      
      return true;
      
    } catch (e) {
      debugPrint('‚ùå [$_logTag] Erreur d√©marrage enregistrement: $e');
      onError?.call('Erreur d√©marrage enregistrement: $e');
      return false;
    }
  }
  
  /// Arr√™te l'enregistrement audio
  Future<bool> stopRecording() async {
    try {
      debugPrint('üõë [$_logTag] ===== D√âBUT ARR√äT ENREGISTREMENT V8 =====');
      
      if (!_isRecording) {
        debugPrint('‚ö†Ô∏è [$_logTag] Aucun enregistrement en cours');
        return true;
      }
      
      debugPrint('üõë [$_logTag] Arr√™t de l\'enregistrement...');
      
      // D√©sactiver la r√©ception audio dans LiveKit
      _liveKitService.stopAcceptingAudioData();
      
      // Arr√™ter la publication audio
      await _liveKitService.unpublishMyAudio();
      
      // Arr√™ter le lecteur audio
      await _audioPlayer.stop();
      
      // Envoyer le message d'arr√™t
      await _sendControlMessage('recording_stopped');
      
      _isRecording = false;
      onRecordingStopped?.call();
      
      debugPrint('‚úÖ [$_logTag] Enregistrement arr√™t√© avec succ√®s');
      debugPrint('üõë [$_logTag] ===== FIN ARR√äT ENREGISTREMENT V8 =====');
      
      return true;
      
    } catch (e) {
      debugPrint('‚ùå [$_logTag] Erreur arr√™t enregistrement: $e');
      onError?.call('Erreur arr√™t enregistrement: $e');
      return false;
    }
  }
  
  /// Traite les donn√©es audio re√ßues de LiveKit
  void handleAudioData(Uint8List audioData) {
    if (!_isInitialized) {
      debugPrint('‚ö†Ô∏è [$_logTag] Adaptateur non initialis√©');
      return;
    }
    
    try {
      _chunksReceived++;
      _lastDataTime = DateTime.now();
      
      debugPrint('üì• [$_logTag] Donn√©es audio re√ßues: ${audioData.length} octets');
      debugPrint('üîÑ [$_logTag] Traitement des donn√©es audio...');
      
      // Analyser et valider les donn√©es audio
      final result = AudioFormatDetectorV2.processAudioData(audioData);
      
      // V√©rifier la validit√© et la qualit√© avec null safety
      final quality = result.quality ?? 0.0;
      if (result.isValid && quality > 0.01) {
        debugPrint('‚úÖ [$_logTag] Donn√©es valid√©es: ${result.format}, qualit√©: ${quality.toStringAsFixed(3)}');
        
        // Utiliser les donn√©es trait√©es ou les donn√©es originales si pas de traitement
        final dataToUse = result.data ?? audioData;
        
        // Convertir PCM16 en WAV et jouer avec just_audio
        _playAudioWithJustAudio(dataToUse);
        _chunksProcessed++;
        
        debugPrint('üéµ [$_logTag] Donn√©es envoy√©es √† just_audio');
        
      } else {
        final errorMsg = result.error ?? 'Qualit√© insuffisante: $quality';
        debugPrint('‚ùå [$_logTag] Donn√©es rejet√©es: $errorMsg');
        _chunksRejected++;
      }
      
    } catch (e) {
      debugPrint('‚ùå [$_logTag] Erreur traitement audio: $e');
      onError?.call('Erreur traitement audio: $e');
    }
  }
  
  /// Joue les donn√©es audio avec just_audio
  void _playAudioWithJustAudio(Uint8List pcmData) async {
    try {
      debugPrint('üéµ [$_logTag] Lecture audio avec just_audio: ${pcmData.length} octets PCM');
      
      // Convertir PCM16 en WAV
      final wavData = _convertPcmToWav(pcmData);
      debugPrint('üîÑ [$_logTag] Conversion PCM‚ÜíWAV: ${pcmData.length} ‚Üí ${wavData.length} octets');
      
      // Cr√©er une source audio personnalis√©e
      final audioSource = PcmStreamAudioSource(wavData);
      
      // Charger et jouer la source audio
      await _audioPlayer.setAudioSource(audioSource);
      await _audioPlayer.play();
      
      debugPrint('‚úÖ [$_logTag] Lecture avec just_audio d√©marr√©e');
      
    } catch (e) {
      debugPrint('‚ùå [$_logTag] Erreur lecture just_audio: $e');
      onError?.call('Erreur lecture audio: $e');
    }
  }
  
  /// Convertit les donn√©es PCM16 en format WAV
  Uint8List _convertPcmToWav(Uint8List pcmData) {
    // Param√®tres audio pour PCM16 48kHz mono
    const int sampleRate = 48000;
    const int numChannels = 1;
    const int bitsPerSample = 16;
    const int byteRate = sampleRate * numChannels * bitsPerSample ~/ 8;
    const int blockAlign = numChannels * bitsPerSample ~/ 8;
    
    // Cr√©er l'en-t√™te WAV
    final header = _createWavHeader(
      pcmData.length,
      sampleRate,
      numChannels,
      bitsPerSample,
      byteRate,
      blockAlign,
    );
    
    // Combiner l'en-t√™te et les donn√©es PCM
    final wavData = Uint8List(header.length + pcmData.length);
    wavData.setRange(0, header.length, header);
    wavData.setRange(header.length, wavData.length, pcmData);
    
    return wavData;
  }
  
  /// Cr√©e l'en-t√™te WAV standard
  Uint8List _createWavHeader(
    int dataSize,
    int sampleRate,
    int numChannels,
    int bitsPerSample,
    int byteRate,
    int blockAlign,
  ) {
    final header = ByteData(44);
    
    // RIFF header
    header.setUint8(0, 0x52); // 'R'
    header.setUint8(1, 0x49); // 'I'
    header.setUint8(2, 0x46); // 'F'
    header.setUint8(3, 0x46); // 'F'
    header.setUint32(4, 36 + dataSize, Endian.little); // File size - 8
    header.setUint8(8, 0x57);  // 'W'
    header.setUint8(9, 0x41);  // 'A'
    header.setUint8(10, 0x56); // 'V'
    header.setUint8(11, 0x45); // 'E'
    
    // Format chunk
    header.setUint8(12, 0x66); // 'f'
    header.setUint8(13, 0x6D); // 'm'
    header.setUint8(14, 0x74); // 't'
    header.setUint8(15, 0x20); // ' '
    header.setUint32(16, 16, Endian.little); // Chunk size
    header.setUint16(20, 1, Endian.little);  // Audio format (PCM)
    header.setUint16(22, numChannels, Endian.little);
    header.setUint32(24, sampleRate, Endian.little);
    header.setUint32(28, byteRate, Endian.little);
    header.setUint16(32, blockAlign, Endian.little);
    header.setUint16(34, bitsPerSample, Endian.little);
    
    // Data chunk
    header.setUint8(36, 0x64); // 'd'
    header.setUint8(37, 0x61); // 'a'
    header.setUint8(38, 0x74); // 't'
    header.setUint8(39, 0x61); // 'a'
    header.setUint32(40, dataSize, Endian.little);
    
    return header.buffer.asUint8List();
  }
  
  /// Traite les donn√©es JSON re√ßues de LiveKit
  void handleJsonData(Map<String, dynamic> jsonData) {
    try {
      debugPrint('üì® [$_logTag] Donn√©es JSON re√ßues: $jsonData');
      
      final type = jsonData['type'] as String?;
      
      switch (type) {
        case 'audio_control':
          _handleAudioControl(jsonData);
          break;
        case 'text_response':
          _handleTextResponse(jsonData);
          break;
        case 'error':
          _handleError(jsonData);
          break;
        default:
          debugPrint('‚ö†Ô∏è [$_logTag] Type de message inconnu: $type');
      }
      
    } catch (e) {
      debugPrint('‚ùå [$_logTag] Erreur traitement JSON: $e');
    }
  }
  
  /// Traite les messages de contr√¥le audio
  void _handleAudioControl(Map<String, dynamic> data) {
    final event = data['event'] as String?;
    debugPrint('üéõÔ∏è [$_logTag] Contr√¥le audio: $event');
    
    switch (event) {
      case 'ia_speech_start':
        debugPrint('üó£Ô∏è [$_logTag] IA commence √† parler');
        break;
      case 'ia_speech_end':
        debugPrint('üîá [$_logTag] IA termine de parler');
        break;
    }
  }
  
  /// Traite les r√©ponses textuelles
  void _handleTextResponse(Map<String, dynamic> data) {
    final text = data['text'] as String?;
    if (text != null && text.isNotEmpty) {
      debugPrint('üìù [$_logTag] Texte re√ßu: $text');
      onTextReceived?.call(text);
    }
  }
  
  /// Traite les erreurs
  void _handleError(Map<String, dynamic> data) {
    final error = data['message'] as String? ?? 'Erreur inconnue';
    debugPrint('‚ùå [$_logTag] Erreur re√ßue: $error');
    onError?.call(error);
  }
  
  /// Envoie un message de contr√¥le
  Future<void> _sendControlMessage(String event) async {
    try {
      final message = {
        'type': 'audio_control',
        'event': event,
        'timestamp': DateTime.now().toIso8601String(),
      };
      
      final jsonString = jsonEncode(message);
      final data = Uint8List.fromList(utf8.encode(jsonString));
      
      await _liveKitService.sendData(data);
      debugPrint('üì§ [$_logTag] Message de contr√¥le envoy√©: $event');
      
    } catch (e) {
      debugPrint('‚ùå [$_logTag] Erreur envoi message: $e');
    }
  }
  
  /// Lib√®re les ressources
  Future<void> dispose() async {
    try {
      debugPrint('üóëÔ∏è [$_logTag] Lib√©ration des ressources...');
      
      if (_isRecording) {
        await stopRecording();
      }
      
      await _audioPlayer.dispose();
      _isInitialized = false;
      
      debugPrint('‚úÖ [$_logTag] Ressources lib√©r√©es');
      
    } catch (e) {
      debugPrint('‚ùå [$_logTag] Erreur lib√©ration: $e');
    }
  }
  
  /// Retourne les statistiques de l'adaptateur
  Map<String, dynamic> getStats() {
    return {
      'isInitialized': _isInitialized,
      'isRecording': _isRecording,
      'isConnected': _isConnected,
      'chunksReceived': _chunksReceived,
      'chunksProcessed': _chunksProcessed,
      'chunksRejected': _chunksRejected,
      'lastDataTime': _lastDataTime?.toIso8601String(),
      'audioPlayerState': _audioPlayer.playerState.toString(),
    };
  }
  
  // Getters pour l'√©tat
  bool get isInitialized => _isInitialized;
  bool get isRecording => _isRecording;
  bool get isConnected => _isConnected;
  
  /// Connecte √† LiveKit avec les informations de session
  Future<bool> connectToLiveKit(SessionModel session) async {
    debugPrint('üîß [$_logTag] ===== D√âBUT CONNEXION V8 =====');
    debugPrint('üîß [$_logTag] Session ID: ${session.sessionId}');
    debugPrint('üîß [$_logTag] Room Name: ${session.roomName}');
    debugPrint('üîß [$_logTag] LiveKit URL: ${session.livekitUrl}');
    
    try {
      // Initialiser l'adaptateur si n√©cessaire
      if (!_isInitialized) {
        final initSuccess = await initialize();
        if (!initSuccess) {
          debugPrint('‚ùå [$_logTag] √âchec de l\'initialisation de l\'adaptateur');
          return false;
        }
      }
      
      // D√©clencher la connexion r√©elle via le service LiveKit
      final success = await _liveKitService.connectWithToken(
        session.livekitUrl,
        session.token,
        roomName: session.roomName,
      );
      
      debugPrint('üîß [$_logTag] R√©sultat connectWithToken: $success');
      
      if (success) {
        _isConnected = true;
        debugPrint('‚úÖ [$_logTag] Connexion LiveKit r√©ussie');
        // Attendre un court d√©lai pour que les callbacks se d√©clenchent
        await Future.delayed(const Duration(milliseconds: 500));
        return true;
      } else {
        debugPrint('‚ùå [$_logTag] √âchec de la connexion LiveKit');
        return false;
      }
    } catch (e, stackTrace) {
      debugPrint('‚ùå [$_logTag] Exception lors de la connexion: $e');
      debugPrint('‚ùå [$_logTag] StackTrace: $stackTrace');
      onError?.call('Erreur de connexion LiveKit: $e');
      return false;
    } finally {
      debugPrint('üîß [$_logTag] ===== FIN CONNEXION V8 =====');
    }
  }
}

/// Source audio personnalis√©e pour just_audio qui lit des donn√©es en m√©moire
class PcmStreamAudioSource extends StreamAudioSource {
  final List<int> bytes;
  
  PcmStreamAudioSource(this.bytes);
  
  @override
  Future<StreamAudioResponse> request([int? start, int? end]) async {
    start ??= 0;
    end ??= bytes.length;
    
    return StreamAudioResponse(
      sourceLength: bytes.length,
      contentLength: end - start,
      offset: start,
      stream: Stream.value(bytes.sublist(start, end)),
      contentType: 'audio/wav',
    );
  }
}
