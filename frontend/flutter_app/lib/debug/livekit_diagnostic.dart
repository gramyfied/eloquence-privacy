import 'dart:io';
import 'package:flutter/material.dart';
import 'package:flutter/services.dart';
import 'package:eloquence_2_0/core/utils/logger_service.dart';
import 'package:device_info_plus/device_info_plus.dart';
import 'package:permission_handler/permission_handler.dart';

class LiveKitDiagnostic {
  static const String _tag = 'LiveKitDiagnostic';
  
  /// Effectue un diagnostic complet du syst√®me Android
  static Future<Map<String, dynamic>> runFullDiagnostic() async {
    final results = <String, dynamic>{};
    
    try {
      // 1. Informations sur l'appareil
      logger.i(_tag, 'üîç === DIAGNOSTIC LIVEKIT ANDROID ===');
      results['device'] = await _getDeviceInfo();
      
      // 2. V√©rification des permissions
      results['permissions'] = await _checkPermissions();
      
      // 3. V√©rification des biblioth√®ques natives
      results['nativeLibs'] = await _checkNativeLibraries();
      
      // 4. Configuration audio
      results['audioConfig'] = await _checkAudioConfiguration();
      
      // 5. V√©rification WebRTC
      results['webrtc'] = await _checkWebRTCSupport();
      
      // Log complet des r√©sultats
      logger.i(_tag, 'üìä R√©sultats du diagnostic:');
      results.forEach((key, value) {
        logger.i(_tag, '$key: $value');
      });
      
      return results;
    } catch (e) {
      logger.e(_tag, '‚ùå Erreur pendant le diagnostic: $e');
      results['error'] = e.toString();
      return results;
    }
  }
  
  /// Obtient les informations de l'appareil
  static Future<Map<String, dynamic>> _getDeviceInfo() async {
    final deviceInfo = DeviceInfoPlugin();
    final info = <String, dynamic>{};
    
    try {
      if (Platform.isAndroid) {
        final androidInfo = await deviceInfo.androidInfo;
        info['model'] = androidInfo.model;
        info['manufacturer'] = androidInfo.manufacturer;
        info['androidVersion'] = androidInfo.version.release;
        info['sdkInt'] = androidInfo.version.sdkInt;
        info['isPhysicalDevice'] = androidInfo.isPhysicalDevice;
        info['supportedAbis'] = androidInfo.supportedAbis;
        info['supported32BitAbis'] = androidInfo.supported32BitAbis;
        info['supported64BitAbis'] = androidInfo.supported64BitAbis;
        
        logger.i(_tag, 'üì± Appareil: ${info['manufacturer']} ${info['model']}');
        logger.i(_tag, 'ü§ñ Android: ${info['androidVersion']} (SDK ${info['sdkInt']})');
        logger.i(_tag, 'üèóÔ∏è ABIs support√©s: ${info['supportedAbis']}');
      }
    } catch (e) {
      logger.e(_tag, '‚ùå Erreur r√©cup√©ration info appareil: $e');
      info['error'] = e.toString();
    }
    
    return info;
  }
  
  /// V√©rifie toutes les permissions n√©cessaires
  static Future<Map<String, String>> _checkPermissions() async {
    final permissions = <String, String>{};
    
    try {
      // Liste des permissions √† v√©rifier
      final permissionsToCheck = {
        'microphone': Permission.microphone,
        'camera': Permission.camera,
        'bluetooth': Permission.bluetooth,
        'bluetoothConnect': Permission.bluetoothConnect,
      };
      
      for (final entry in permissionsToCheck.entries) {
        final status = await entry.value.status;
        permissions[entry.key] = status.toString();
        logger.i(_tag, 'üîê Permission ${entry.key}: $status');
      }
      
      // V√©rifier si les permissions audio sont accord√©es au runtime
      if (Platform.isAndroid) {
        final audioStatus = await Permission.microphone.status;
        if (!audioStatus.isGranted) {
          logger.w(_tag, '‚ö†Ô∏è Permission microphone non accord√©e!');
        }
      }
    } catch (e) {
      logger.e(_tag, '‚ùå Erreur v√©rification permissions: $e');
      permissions['error'] = e.toString();
    }
    
    return permissions;
  }
  
  /// V√©rifie la pr√©sence des biblioth√®ques natives
  static Future<Map<String, dynamic>> _checkNativeLibraries() async {
    final libs = <String, dynamic>{};
    
    try {
      // V√©rifier si certaines biblioth√®ques critiques sont pr√©sentes
      // Note: Cette v√©rification est limit√©e car Flutter n'a pas d'acc√®s direct aux libs natives
      
      // Essayer de charger les biblioth√®ques WebRTC
      try {
        // Cette approche tente d'utiliser les biblioth√®ques via JNI
        const platform = MethodChannel('com.example.eloquence_2_0/native_check');
        final result = await platform.invokeMethod('checkNativeLibraries');
        libs['nativeCheck'] = result;
      } catch (e) {
        logger.w(_tag, '‚ö†Ô∏è Impossible de v√©rifier les libs natives directement: $e');
        libs['directCheck'] = 'Non disponible';
      }
      
      // V√©rifier l'architecture de l'appareil
      if (Platform.isAndroid) {
        final deviceInfo = DeviceInfoPlugin();
        final androidInfo = await deviceInfo.androidInfo;
        libs['currentAbi'] = androidInfo.supportedAbis.isNotEmpty 
            ? androidInfo.supportedAbis.first 
            : 'unknown';
        logger.i(_tag, 'üèóÔ∏è Architecture actuelle: ${libs['currentAbi']}');
      }
      
    } catch (e) {
      logger.e(_tag, '‚ùå Erreur v√©rification libs natives: $e');
      libs['error'] = e.toString();
    }
    
    return libs;
  }
  
  /// V√©rifie la configuration audio Android
  static Future<Map<String, dynamic>> _checkAudioConfiguration() async {
    final audioConfig = <String, dynamic>{};
    
    try {
      // V√©rifier les param√®tres audio syst√®me
      audioConfig['audioMode'] = 'NORMAL'; // Par d√©faut
      
      // Essayer d'obtenir des infos via platform channel
      try {
        const platform = MethodChannel('com.example.eloquence_2_0/audio_config');
        final result = await platform.invokeMethod('getAudioConfiguration');
        audioConfig.addAll(result as Map<String, dynamic>);
      } catch (e) {
        logger.w(_tag, '‚ö†Ô∏è Impossible d\'obtenir la config audio native: $e');
      }
      
      logger.i(_tag, 'üîä Configuration audio: $audioConfig');
      
    } catch (e) {
      logger.e(_tag, '‚ùå Erreur v√©rification config audio: $e');
      audioConfig['error'] = e.toString();
    }
    
    return audioConfig;
  }
  
  /// V√©rifie le support WebRTC
  static Future<Map<String, dynamic>> _checkWebRTCSupport() async {
    final webrtcInfo = <String, dynamic>{};
    
    try {
      // V√©rifier la version de flutter_webrtc
      webrtcInfo['flutter_webrtc_version'] = '0.14.1'; // Version dans pubspec.yaml
      
      // V√©rifier si WebRTC peut √™tre initialis√©
      try {
        // Note: L'initialisation r√©elle se fait dans LiveKitService
        webrtcInfo['canInitialize'] = true;
        logger.i(_tag, '‚úÖ WebRTC semble pouvoir √™tre initialis√©');
      } catch (e) {
        webrtcInfo['canInitialize'] = false;
        webrtcInfo['initError'] = e.toString();
        logger.e(_tag, '‚ùå WebRTC ne peut pas √™tre initialis√©: $e');
      }
      
    } catch (e) {
      logger.e(_tag, '‚ùå Erreur v√©rification WebRTC: $e');
      webrtcInfo['error'] = e.toString();
    }
    
    return webrtcInfo;
  }
  
  /// Affiche un rapport de diagnostic dans une dialog
  static Future<void> showDiagnosticDialog(BuildContext context) async {
    showDialog(
      context: context,
      barrierDismissible: false,
      builder: (context) => const Center(
        child: CircularProgressIndicator(),
      ),
    );
    
    final results = await runFullDiagnostic();
    
    if (context.mounted) {
      Navigator.of(context).pop();
      
      showDialog(
        context: context,
        builder: (context) => AlertDialog(
          title: const Text('Diagnostic LiveKit'),
          content: SingleChildScrollView(
            child: Column(
              crossAxisAlignment: CrossAxisAlignment.start,
              mainAxisSize: MainAxisSize.min,
              children: [
                _buildSection('Appareil', results['device']),
                _buildSection('Permissions', results['permissions']),
                _buildSection('Biblioth√®ques natives', results['nativeLibs']),
                _buildSection('Configuration audio', results['audioConfig']),
                _buildSection('Support WebRTC', results['webrtc']),
              ],
            ),
          ),
          actions: [
            TextButton(
              onPressed: () => Navigator.of(context).pop(),
              child: const Text('Fermer'),
            ),
          ],
        ),
      );
    }
  }
  
  static Widget _buildSection(String title, dynamic data) {
    return Padding(
      padding: const EdgeInsets.symmetric(vertical: 8.0),
      child: Column(
        crossAxisAlignment: CrossAxisAlignment.start,
        children: [
          Text(
            title,
            style: const TextStyle(
              fontWeight: FontWeight.bold,
              fontSize: 16,
            ),
          ),
          const SizedBox(height: 4),
          if (data is Map)
            ...data.entries.map((e) => Padding(
              padding: const EdgeInsets.only(left: 16.0),
              child: Text('${e.key}: ${e.value}'),
            ))
          else
            Padding(
              padding: const EdgeInsets.only(left: 16.0),
              child: Text(data.toString()),
            ),
        ],
      ),
    );
  }
}